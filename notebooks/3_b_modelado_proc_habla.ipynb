{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## **Estructura de sub-etapas del procesamiento del habla:**\n",
        "\n",
        "---\n",
        "\n",
        "```\n",
        "├── Input Layer\n",
        "│   ├── Audio Capture\n",
        "│   └── ASR (Speech-to-Text)\n",
        "├── NLP Layer\n",
        "│   ├── Text Preprocessing\n",
        "│   ├── Intent Detection\n",
        "│   ├── Entity Recognition\n",
        "│   └── Sentiment Analysis\n",
        "├── Dialogue Management\n",
        "│   ├── State Management\n",
        "│   ├── Response Generation\n",
        "│   ├── Response Selection\n",
        "│   └── Context Handling\n",
        "├── Output Layer\n",
        "│   ├── TTS (Text-to-Speech)\n",
        "│   └── Audio Playback\n",
        "\n",
        "```\n"
      ],
      "metadata": {
        "id": "XTpu7pHup5pq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Estructura operativa para cada etapa:**\n",
        "\n",
        "**Selección de técnicas de modelado:** En este caso se utilizara [] para la etapa de reconocimiento de voz, [] para el procesamiento y analisis de texto y [] para la conversion de texto a voz.\n",
        "\n",
        "**Generación de un diseño de comprobación:** Para elegir el modelo correcto, este devera ser el que pondere mas alto en un promedio de las diferentes metricas de evaluacion del modelo.\n",
        "\n",
        "**Generación de los modelos:** Se definiran y configuraran los parametros del modelo para pasar a la etapa de ejecucion y descripcion.\n",
        "\n",
        "**Evaluación del modelo:** Se evaluaran los diferentes modelos de manera individual en busqueda de optimizar sus parametros y escoger la combinacion mas optima entre modelos / parametros individuales."
      ],
      "metadata": {
        "id": "ba_DUci1CkX6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files"
      ],
      "metadata": {
        "id": "JM_Jd-w3lOWe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Utilizo la ultima version de python compatible con deepspeech\n",
        "%%bash\n",
        "apt-get update\n",
        "apt-get install python3\n",
        "apt-get install -venv\n",
        "python3 -m venv proc_habla\n",
        "source proc_habla/bin/activate"
      ],
      "metadata": {
        "id": "oTkfaLx7boQi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "uploaded = files.upload()"
      ],
      "metadata": {
        "id": "j8D2WjCXcnNR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **1. Entrada de Usuario (Reconocimiento del Habla)**"
      ],
      "metadata": {
        "id": "T0MT6XY2qoIA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip3 install SpeechRecognition\n",
        "!pip3 install sounddevice scipy"
      ],
      "metadata": {
        "id": "yIsbz7_HkZZJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import speech_recognition as sr\n",
        "import numpy as np\n",
        "import wave\n",
        "import sounddevice as sd\n",
        "from scipy.io.wavfile import write\n",
        "import queue\n",
        "import threading"
      ],
      "metadata": {
        "id": "eQgslv4y1nrF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Módulo de Captura de Audio:**"
      ],
      "metadata": {
        "id": "mxPsnrV6riGR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Configuración de los parámetros de grabación\n",
        "SAMPLE_RATE = 44100  # Tasa de muestreo\n",
        "DURATION = 5  # Duración de la grabación en segundos\n",
        "FILENAME = \"output.wav\"  # Nombre del archivo de salida"
      ],
      "metadata": {
        "id": "8bLph4ehd_0_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def record_audio(filename, duration, sample_rate):\n",
        "    print(\"Grabando...\")\n",
        "\n",
        "    # Grabar audio\n",
        "    recording = sd.rec(int(duration * sample_rate), samplerate=sample_rate, channels=2)\n",
        "    sd.wait()  # Esperar a que termine la grabación\n",
        "\n",
        "    print(\"Grabación finalizada\")\n",
        "    # Guardar la grabación en un archivo WAV\n",
        "    write(filename, sample_rate, recording)\n",
        "\n",
        "    return filename\n",
        "\n",
        "def process_audio():\n",
        "    # Esta función podría hacer más cosas, como enviar el archivo de audio a un servicio de reconocimiento de voz\n",
        "    filename = record_audio(FILENAME, DURATION, SAMPLE_RATE)\n",
        "    print(f\"Audio guardado en {filename}\")\n",
        "\n",
        "# Ejemplo de cómo integrar esto en un flujo de un chatbot\n",
        "def chatbot():\n",
        "    while True:\n",
        "        user_input = input(\"Di algo (o escribe 'grabar' para grabar audio, 'salir' para terminar): \")\n",
        "        if user_input.lower() == 'salir':\n",
        "            break\n",
        "        elif user_input.lower() == 'grabar':\n",
        "            process_audio()\n",
        "        else:\n",
        "            print(f\"Tú dijiste: {user_input}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    chatbot()"
      ],
      "metadata": {
        "id": "5W7StwLecqQV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Reconocimiento del Habla (ASR - Automatic Speech Recognition):**"
      ],
      "metadata": {
        "id": "c6PxS_YcrlCZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Crear un objeto Recognizer\n",
        "recognizer = sr.Recognizer()"
      ],
      "metadata": {
        "id": "YfbVSNU0m3N4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xEwSWIZcp4zp"
      },
      "outputs": [],
      "source": [
        "# Abrir el archivo de audio\n",
        "def transcribe_audio(audio_fiel_path, audio_lang):\n",
        "  with sr.AudioFile('audio_file.wav') as source:\n",
        "      # Escuchar el audio (en inglés)\n",
        "      audio = recognizer.record(source)\n",
        "\n",
        "      # Utilizar Google Speech Recognition para transcribir el audio\n",
        "      try:\n",
        "          text = recognizer.recognize_google(audio, language='es-ES')\n",
        "          print(\"Transcripción: \", text)\n",
        "          return text\n",
        "      except sr.UnknownValueError:\n",
        "          print(\"No se pudo entender el audio\")\n",
        "      except sr.RequestError as e:\n",
        "          print(\"Error al solicitar resultados del servicio Google Speech Recognition; {0}\".format(e))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Ruta al archivo de audio que deseas transcribir en español\n",
        "audio_file_path = 'path/to/your/audio_file.wav'\n",
        "audio_lang = 'es'"
      ],
      "metadata": {
        "id": "sK32Iyq1Y7QR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Transcribir y mostrar el resultado\n",
        "text = transcribe_audio(audio_file_path, audio_lang)"
      ],
      "metadata": {
        "id": "pxpKQFiNm7m-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **2. Procesamiento del Lenguaje Natural (NLP)**"
      ],
      "metadata": {
        "id": "AcUSQzM7qsxY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Preprocesamiento de Texto:**\n"
      ],
      "metadata": {
        "id": "HDaWq5syqu6m"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "**Normalización del texto (eliminación de ruido, corrección ortográfica, etc.)**"
      ],
      "metadata": {
        "id": "FLfTLCw2q8IM"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "B6Br9PyerAkd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Tokenización**"
      ],
      "metadata": {
        "id": "vrKl19tGq9KJ"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "f5IX1gghrBXD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Eliminación de stop words.**\n"
      ],
      "metadata": {
        "id": "xVbV-FF5q-af"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "TY1ASrUnrB3I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Lematización y stemming**"
      ],
      "metadata": {
        "id": "Lt4d5DQcq_xW"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZkAeKi67rCfu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Análisis de Texto:**\n"
      ],
      "metadata": {
        "id": "C9ZvYH9dq1GY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Análisis de Sentimiento: Determinar la emoción o tono del texto.\n"
      ],
      "metadata": {
        "id": "wSCEB3hpr2y6"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QtrOgErkr4PD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Detección de Intenciones (Intent Detection): Identificar la intención del usuario utilizando modelos como BERT, GPT, RASA, etc.\n"
      ],
      "metadata": {
        "id": "hzhTpz0qr4lW"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lEYOkzT7r8Pj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Extracción de Entidades (Entity Recognition): Extraer información relevante del texto, como nombres, fechas, ubicaciones, etc."
      ],
      "metadata": {
        "id": "QI6hMGhzr8mg"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xgG3V-bCq2Ii"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **3. Gestión del Diálogo**"
      ],
      "metadata": {
        "id": "_ibsChXBsNdX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Módulo de Gestión de Estado:\n",
        "Llevar un registro del contexto y estado del diálogo para mantener conversaciones coherentes.\n"
      ],
      "metadata": {
        "id": "zEnB65VssQvq"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3ECriCX3sVWu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Motor de Respuesta:\n"
      ],
      "metadata": {
        "id": "BByh2AXGsVmJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Generación de Respuestas: Utilizar modelos generativos (como GPT-3) o respuestas predefinidas según las intenciones y entidades detectadas.\n"
      ],
      "metadata": {
        "id": "j15ewWSasb4F"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UjnjzK3gseaL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Selección de Respuestas: Elegir la mejor respuesta entre varias opciones generadas.\n"
      ],
      "metadata": {
        "id": "xgvv-ETKsenO"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3t1AFBk2sf1P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Personalización y Contexto: Adaptar las respuestas en función del historial del usuario y el contexto actual."
      ],
      "metadata": {
        "id": "QntMxU6_shpm"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MU_3as2dsi2S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Salida de Usuario (Text-to-Speech)\n"
      ],
      "metadata": {
        "id": "9-sSu2b0soDe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Conversión de Texto a Voz (TTS): Utilizar servicios como Google Text-to-Speech, Amazon Polly, o frameworks como Tacotron para convertir el texto generado en voz.\n"
      ],
      "metadata": {
        "id": "q5eR9QLTssCK"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "kzi_CA2tswVF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Reproducción de Audio: Entregar la respuesta de voz al usuario."
      ],
      "metadata": {
        "id": "u3TVK99Wswe8"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "TOKovFuVsyaD"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}