{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# **Procesamiento del habla**\n",
        "\n",
        "**VERSION 1.0**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Funcionalidades versionadas:\n",
        "\n",
        "VER 1.0\n",
        "- Uso de dataset filtrado por frutas y verduras\n",
        "- Entrada de consulta para un producto por vez\n",
        "- Recomendación para el cliente:\n",
        "    - Algoritmo de ordenamiento basado en preferencias del usuario (dentro de la estructura gramatical):\n",
        "        - Características particulares del producto.\n",
        "            - Basado en el precio.\n",
        "            - Generales\n",
        "\n",
        "*VER 1.3:*\n",
        "- Entrada de consulta para más de un producto.\n",
        "- Recomendaciones basadas en análisis de sentimiento.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XTpu7pHup5pq"
      },
      "source": [
        "## Estructura de sub-etapas\n",
        "--- \n",
        "```\n",
        "├── Reconocimiento del lenguaje\n",
        "│ ├── Captura de texto\n",
        "│ └── Captura de audio\n",
        "├── Procesamiento del lenguaje\n",
        "│ ├── Preprocesamiento de texto\n",
        "│ └── Análisis de texto\n",
        "├── Gestión de respuesta\n",
        "│ ├── Gestión del estado\n",
        "│ ├── Motor de respuesta\n",
        "│ └── Personalización\n",
        "├── Texto a voz\n",
        "│ └── Conversión de texto a voz\n",
        "\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ba_DUci1CkX6"
      },
      "source": [
        "En esta etapa, se utilizaran varias librerías clave para diferentes etapas del proceso de recomendación basado en la entrada del usuario. Las principales librerías empleadas serán: SpeechRecognition para la transcripción de voz a texto, spaCy para el procesamiento y análisis del texto, y Google Text-to-Speech (gTTS) para convertir texto a voz.\n",
        "\n",
        "El proceso comenzará con la captura de la entrada del usuario a través de texto directo o por voz mediante SpeechRecognition, que transformará la voz en texto. Este texto será procesado con spaCy para extraer y lematizar tokens, filtrando específicamente adjetivos, sustantivos y proposiciones. Simultáneamente, se analizarán los productos en nuestro dataframe mediante spaCy, lematizando y filtrando tokens relevantes de la misma manera.\n",
        "\n",
        "Luego, compararemos los tokens procesados de la entrada del usuario con los tokens procesados de los productos, para evaluar la similitud. Durante esta comparación, también verificaremos si algún token es sinónimo de adjetivos relacionados con el precio del producto. Con esta información, generaremos dos listas de productos: una ordenada por la coincidencia general de los tokens y otra por el precio, en orden ascendente.\n",
        "\n",
        "Finalmente, ambas listas se integrarán en una recomendación que se almacenará en un diccionario, vinculada al índice del producto en la tabla original. Esta recomendación se convertirá a voz mediante Google Text-to-Speech y se entregará al usuario dentro de un diccionario, proporcionando una experiencia interactiva y personalizada."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Librerias y paquetes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### *Entorno virtuales*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create and activate virtual env for speech processing stage\n",
        "!python3 -m venv proc_habla\n",
        "!source proc_habla/bin/activate"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### *Instalacion*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: scipy in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (1.11.1)\n",
            "Requirement already satisfied: numpy<1.28.0,>=1.21.6 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from scipy) (1.25.2)\n",
            "Requirement already satisfied: SpeechRecognition in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (3.10.4)\n",
            "Requirement already satisfied: requests>=2.26.0 in /Users/cristianariel/Library/Python/3.11/lib/python/site-packages (from SpeechRecognition) (2.31.0)\n",
            "Requirement already satisfied: typing-extensions in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from SpeechRecognition) (4.8.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/cristianariel/Library/Python/3.11/lib/python/site-packages (from requests>=2.26.0->SpeechRecognition) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /Users/cristianariel/Library/Python/3.11/lib/python/site-packages (from requests>=2.26.0->SpeechRecognition) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/cristianariel/Library/Python/3.11/lib/python/site-packages (from requests>=2.26.0->SpeechRecognition) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from requests>=2.26.0->SpeechRecognition) (2024.6.2)\n",
            "Requirement already satisfied: gtts in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (2.5.1)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /Users/cristianariel/Library/Python/3.11/lib/python/site-packages (from gtts) (2.31.0)\n",
            "Requirement already satisfied: click<8.2,>=7.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from gtts) (8.1.7)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/cristianariel/Library/Python/3.11/lib/python/site-packages (from requests<3,>=2.27->gtts) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /Users/cristianariel/Library/Python/3.11/lib/python/site-packages (from requests<3,>=2.27->gtts) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/cristianariel/Library/Python/3.11/lib/python/site-packages (from requests<3,>=2.27->gtts) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from requests<3,>=2.27->gtts) (2024.6.2)\n",
            "Requirement already satisfied: spacy in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (3.7.4)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from spacy) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from spacy) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from spacy) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from spacy) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from spacy) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from spacy) (8.2.3)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from spacy) (1.1.2)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from spacy) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from spacy) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.4.0,>=0.1.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from spacy) (0.3.4)\n",
            "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from spacy) (0.9.0)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from spacy) (6.4.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from spacy) (4.66.1)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /Users/cristianariel/Library/Python/3.11/lib/python/site-packages (from spacy) (2.31.0)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from spacy) (2.6.3)\n",
            "Requirement already satisfied: jinja2 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from spacy) (3.1.2)\n",
            "Requirement already satisfied: setuptools in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from spacy) (65.5.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /Users/cristianariel/Library/Python/3.11/lib/python/site-packages (from spacy) (23.1)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from spacy) (3.4.0)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from spacy) (1.25.2)\n",
            "Requirement already satisfied: language-data>=1.2 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from langcodes<4.0.0,>=3.2.0->spacy) (1.2.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.16.3 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.16.3)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.8.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/cristianariel/Library/Python/3.11/lib/python/site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /Users/cristianariel/Library/Python/3.11/lib/python/site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/cristianariel/Library/Python/3.11/lib/python/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2024.6.2)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from thinc<8.3.0,>=8.2.2->spacy) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from thinc<8.3.0,>=8.2.2->spacy) (0.1.4)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from typer<0.10.0,>=0.3.0->spacy) (8.1.7)\n",
            "Requirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from weasel<0.4.0,>=0.1.0->spacy) (0.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from jinja2->spacy) (2.1.3)\n",
            "Requirement already satisfied: marisa-trie>=0.7.7 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy) (1.1.1)\n"
          ]
        }
      ],
      "source": [
        "# Librerías de preprocesamiento\n",
        "!pip3 install scipy\n",
        "\n",
        "# Librerías de reconocimiento de voz\n",
        "!pip3 install SpeechRecognition\n",
        "\n",
        "# Librerías de generación de voz\n",
        "!pip3 install gtts\n",
        "\n",
        "# Librerías de análisis lingüístico\n",
        "!pip3 install spacy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting es-core-news-sm==3.7.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/es_core_news_sm-3.7.0/es_core_news_sm-3.7.0-py3-none-any.whl (12.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.9/12.9 MB\u001b[0m \u001b[31m292.0 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:02\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: spacy<3.8.0,>=3.7.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from es-core-news-sm==3.7.0) (3.7.4)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (8.2.3)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (1.1.2)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.4.0,>=0.1.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (0.3.4)\n",
            "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (0.9.0)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (6.4.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (4.66.1)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /Users/cristianariel/Library/Python/3.11/lib/python/site-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (2.31.0)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (2.6.3)\n",
            "Requirement already satisfied: jinja2 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (3.1.2)\n",
            "Requirement already satisfied: setuptools in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (65.5.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /Users/cristianariel/Library/Python/3.11/lib/python/site-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (23.1)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (3.4.0)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (1.25.2)\n",
            "Requirement already satisfied: language-data>=1.2 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (1.2.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.16.3 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (2.16.3)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (4.8.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/cristianariel/Library/Python/3.11/lib/python/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /Users/cristianariel/Library/Python/3.11/lib/python/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/cristianariel/Library/Python/3.11/lib/python/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (2024.6.2)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (0.1.4)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from typer<0.10.0,>=0.3.0->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (8.1.7)\n",
            "Requirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from weasel<0.4.0,>=0.1.0->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (0.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from jinja2->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (2.1.3)\n",
            "Requirement already satisfied: marisa-trie>=0.7.7 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (1.1.1)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('es_core_news_sm')\n"
          ]
        }
      ],
      "source": [
        "# Descargo el modelo de la libreria spacy pre-entrenado con corpus en Español\n",
        "!python3 -m spacy download es_core_news_sm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### *Importacion*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Librerías para reconocimiento de voz y procesamiento de audio\n",
        "import speech_recognition as sr\n",
        "\n",
        "# Librerías para manipulación de archivos y compresión\n",
        "import os\n",
        "import io\n",
        "\n",
        "# Librerías para procesamiento de datos y análisis\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import spacy\n",
        "from spacy import displacy\n",
        "import re\n",
        "\n",
        "# Librería para generación de voz\n",
        "from gtts import gTTS\n",
        "\n",
        "# Importación de funciones comunes a otros cuadernos\n",
        "from funciones_comunes import common_functions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Funciones"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Captura de texto de entrada"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "def entrada_texto():\n",
        "    texto = input('Ingresa brevemente el producto que deseas comprar y sus características: ')\n",
        "    return texto"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Reconocimiento del Habla (ASR - Automatic Speech Recognition):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "def entrada_voz():\n",
        "    recognizer = sr.Recognizer()  # Se inicializa el objeto de la clase speech recognition con el metodo recognizer y almacena en la variable 'recognizer'\n",
        "    mic = sr.Microphone()  # Configuración del micrófono como fuente de audio\n",
        "\n",
        "    with mic as source:\n",
        "        recognizer.adjust_for_ambient_noise(source, duration=1)\n",
        "        # Ajuste de sensibilidad y tiempo de pausa\n",
        "        recognizer.energy_threshold = 300  # Ajustar según el entorno\n",
        "        recognizer.pause_threshold = 1.0  # Ajustar según necesidad\n",
        "        print(\"Por favor, habla ahora.\")  # Indicación para el usuario\n",
        "        audio = recognizer.listen(source)  # Escucha y captura del audio mientras escuche entrada de voz continua\n",
        "\n",
        "    try:\n",
        "        texto = recognizer.recognize_google(audio, language='es-ES')  # Reconocimiento de voz utilizando Google\n",
        "    except sr.UnknownValueError:\n",
        "        print(\"No se pudo entender el audio\")  # Manejo de error en caso de audio no reconocido\n",
        "    except sr.RequestError as e:\n",
        "        print(\"Error al conectarse con el servicio de Google: {0}\".format(e))  # Manejo de error en la conexión con Google\n",
        "\n",
        "    return texto  # retorna el texto reconocido por audio"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Comprovacion de sinonimos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "def verifica_sinonimo_precios(tokens, sinonimos):\n",
        "    '''\n",
        "    Esta función verifica si dentro de la lista de tokens proporcionada como primer parámetro\n",
        "    se encuentra un sinónimo o derivación morfológica de alguna de las palabras dentro del diccionario de sinónimos.\n",
        "\n",
        "    Args:\n",
        "    'tokens': Recibe los tokens lematizados de la entrada del usuario.\n",
        "    'sinonimos': Diccionario de sinónimos para las referencias.\n",
        "\n",
        "    Retorno:\n",
        "    Esta función retorna como resultado 'True' o 'False', según corresponda.\n",
        "    '''\n",
        "    # Convertir la lista de tokens a un conjunto para mejorar la eficiencia de búsqueda\n",
        "    tokens_set = set(tokens)\n",
        "    print(tokens_set)\n",
        "    # Recorrer todos los sinónimos en el diccionario\n",
        "    for sinonimos_list in sinonimos.values():\n",
        "        for sinonimo in sinonimos_list:\n",
        "            if sinonimo in tokens_set:\n",
        "                return True\n",
        "                \n",
        "    return False"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Lectura de datos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### *Datos fuentes*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Defino el diccionario donde se almacenara la informacion de entrada y salida de la consulta\n",
        "consulta_dict = {}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Lectura y almacenado del dataframe\n",
        "path_csv_rutas_verduras = '../../datos/procesaodos/VerdurasporSupermercado.csv'\n",
        "df_frutas_verduras = pd.read_csv(path_csv_rutas_verduras)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T0MT6XY2qoIA"
      },
      "source": [
        "## 1. Reconocimiento del Habla\n",
        "\n",
        "___"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### a. Captura de entradas de texto"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Conexión con la API de FastAPI\n",
        "# Aquí iría la conexión con un script encargado de conectar con la API de FastAPI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Función tentativa para recibir la entrada de texto desde FastAPI\n",
        "# funcion definida al comienzo del notebook"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### b. Captura de Audio"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c6PxS_YcrlCZ"
      },
      "source": [
        "#### Reconocimiento del Habla (ASR - Automatic Speech Recognition):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "# funcion definida al comienzo del notebook"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### c. Identificar tipo de entrada"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Tipo de entrada específica pasada por fast-api\n",
        "entrada_tipo = ''\n",
        "\n",
        "# ejecucion de funciones de entrada segun corresponda la modalidad / tipo de la misma\n",
        "if entrada_tipo == 'audio':\n",
        "    texto = entrada_voz()  # Si la entrada es de tipo 'audio', se utiliza la función para recibir entrada de voz\n",
        "elif entrada_tipo == 'texto':\n",
        "    texto = entrada_texto()  # Si la entrada es de tipo 'texto', se utiliza la función para recibir entrada de texto\n",
        "else:\n",
        "    # Se define texto de prueba en caso de que no se espesifique el tipo de entrada\n",
        "    texto = 'Quiero tomates rojos, grandes y economicos'\n",
        "    pass"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AcUSQzM7qsxY"
      },
      "source": [
        "## 2. Procesamiento del Lenguaje Natural\n",
        "\n",
        "___"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cargar el modelo de spaCy para español\n",
        "nlp = spacy.load(\"es_core_news_sm\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HDaWq5syqu6m"
      },
      "source": [
        "### Preprocesamiento de texto\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "\"\\n\\n# unidades_medida_peso = ['g', 'gr', 'kg', 'mg', 'µg', 't', 'lb', 'oz', 'cwt',\\n                        #'gramos', 'kilogramos', 'miligramos', 'microgramos',\\n                        #'toneladas', 'libras', 'onzas', 'quintales']\\n\\n\""
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Lista de abreviaturas y formas no abreviadas de unidades de medida de peso\n",
        "'''\n",
        "\n",
        "# unidades_medida_peso = ['g', 'gr', 'kg', 'mg', 'µg', 't', 'lb', 'oz', 'cwt',\n",
        "                        #'gramos', 'kilogramos', 'miligramos', 'microgramos',\n",
        "                        #'toneladas', 'libras', 'onzas', 'quintales']\n",
        "\n",
        "'''"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FLfTLCw2q8IM"
      },
      "source": [
        "#### *Normalización del texto*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "B6Br9PyerAkd"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<span class=\"tex2jax_ignore\"><svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"es\" id=\"d95e03f140b74db891b8e2654b3a22da-0\" class=\"displacy\" width=\"650\" height=\"237.0\" direction=\"ltr\" style=\"max-width: none; height: 237.0px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"147.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">quiero</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">VERB</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"147.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"150\">tomates</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"150\">NOUN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"147.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"250\">rojos</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"250\">ADJ</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"147.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"350\">grandes</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"350\">ADJ</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"147.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"450\">y</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"450\">CCONJ</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"147.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"550\">economicos</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"550\">ADJ</tspan>\n",
              "</text>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-d95e03f140b74db891b8e2654b3a22da-0-0\" stroke-width=\"2px\" d=\"M70,102.0 C70,52.0 145.0,52.0 145.0,102.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-d95e03f140b74db891b8e2654b3a22da-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M145.0,104.0 L153.0,92.0 137.0,92.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-d95e03f140b74db891b8e2654b3a22da-0-1\" stroke-width=\"2px\" d=\"M170,102.0 C170,52.0 245.0,52.0 245.0,102.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-d95e03f140b74db891b8e2654b3a22da-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">amod</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M245.0,104.0 L253.0,92.0 237.0,92.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-d95e03f140b74db891b8e2654b3a22da-0-2\" stroke-width=\"2px\" d=\"M170,102.0 C170,2.0 350.0,2.0 350.0,102.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-d95e03f140b74db891b8e2654b3a22da-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">amod</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M350.0,104.0 L358.0,92.0 342.0,92.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-d95e03f140b74db891b8e2654b3a22da-0-3\" stroke-width=\"2px\" d=\"M470,102.0 C470,52.0 545.0,52.0 545.0,102.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-d95e03f140b74db891b8e2654b3a22da-0-3\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">cc</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M470,104.0 L462,92.0 478,92.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-d95e03f140b74db891b8e2654b3a22da-0-4\" stroke-width=\"2px\" d=\"M370,102.0 C370,2.0 550.0,2.0 550.0,102.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-d95e03f140b74db891b8e2654b3a22da-0-4\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">conj</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M550.0,104.0 L558.0,92.0 542.0,92.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "</svg></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# texto procesado por la funcion 'common_functions.procesar_texto'\n",
        "texto_analizado = common_functions.procesar_texto(texto, graph=True, nlp = nlp)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vrKl19tGq9KJ"
      },
      "source": [
        "#### *Tokenización*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "f5IX1gghrBXD"
      },
      "outputs": [],
      "source": [
        "# tokens del texto procesado\n",
        "tokens = texto_analizado['tokens']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xVbV-FF5q-af"
      },
      "source": [
        "#### *Eliminación de stop words*\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "TY1ASrUnrB3I"
      },
      "outputs": [],
      "source": [
        "# Tokens filtrados\n",
        "tokens_filtrados = texto_analizado['filtered_tokens']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lt4d5DQcq_xW"
      },
      "source": [
        "#### *Lematización*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "ZkAeKi67rCfu"
      },
      "outputs": [],
      "source": [
        "# lemas de los tokens filtrados\n",
        "lemmas_filtrados = texto_analizado['lemmas']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### *Etiquetado de estructuras gramaticales*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [],
      "source": [
        "# etiquetas gramaticales de los tokens filtrados\n",
        "pos_tags_filtrados = texto_analizado['pos_tags']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C9ZvYH9dq1GY"
      },
      "source": [
        "### Análisis de texto\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Deteccion de sinonimos de preferencias basadas en el precio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'economico', 'rojo', 'tomate'}\n"
          ]
        }
      ],
      "source": [
        "# Lista de sinónimos para las referencias\n",
        "sinonimos = {\n",
        "    \"económico\": [\"barato\", \"asequible\", \"económico\"],\n",
        "    \"barato\": [\"económico\", \"asequible\", \"barato\"],\n",
        "    \"asequible\": [\"económico\", \"barato\", \"asequible\"],\n",
        "    \"precio\": [\"coste\", \"precio\"],\n",
        "    \"coste\": [\"precio\", \"coste\"]\n",
        "}\n",
        "\n",
        "# Verificar si hay algún sinónimo o derivación en los tokens lematizados\n",
        "consulta_precio = verifica_sinonimo_precios(lemmas_filtrados, sinonimos=sinonimos)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Detectar presencia de palabras de productos lematizadas dentro de dataframe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [],
      "source": [
        "# carga del conjunto de datos en dataframe\n",
        "df_frutas_verduras['producto_tokens_lemmas'] = df_frutas_verduras['Producto'].apply(lambda x: common_functions.procesar_texto(x, nlp = nlp)['lemmas'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Diccionario de coincidencias entre tokens lematizados de la columna y la entrada del usuario\n",
        "dict_count_coincidences = {}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Algoritmos predefinidos de clasificacion según las intenciones y preferencias detectadas.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Algoritmo para contar coincidencias entre tokens lematizados de la entrada del usuario y la columna/fila del DataFrame\n",
        "for index, row in df_frutas_verduras.iterrows():  # Iterar sobre las filas del DataFrame\n",
        "    for token_producto in row['producto_tokens_lemmas']:  # Iterar sobre los tokens lematizados de la columna 'producto_tokens_lemmas'\n",
        "        if token_producto in lemmas_filtrados:  # Verificar si el token lematizado está en la lista de lemas filtrados de la entrada del usuario\n",
        "            if token_producto not in dict_count_coincidences:  # Si el token no está en el diccionario de coincidencias\n",
        "                dict_count_coincidences[index] = 1  # Agregar el token al diccionario con el valor 1\n",
        "            else:  # Si el token ya está en el diccionario de coincidencias\n",
        "                dict_count_coincidences[index] += 1  # Incrementar el valor del token en el diccionario"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Se transforma el diccionario a una seria de python para luego poder ordenarla por valor\n",
        "series_ordered_count_coincidences = pd.Series(dict_count_coincidences)\n",
        "\n",
        "# Asegurar que series_ordered_count_coincidences es una Serie ordenada\n",
        "series_ordered_count_coincidences = series_ordered_count_coincidences.sort_values(ascending=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wSCEB3hpr2y6"
      },
      "source": [
        "Análisis de Sentimiento: Determinar la emoción o tono del texto.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "QtrOgErkr4PD"
      },
      "outputs": [],
      "source": [
        "# se desarrollara en futuras versiones"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hzhTpz0qr4lW"
      },
      "source": [
        "Detección de Intenciones (Intent Detection): Identificar la intención del usuario utilizando modelos como BERT, GPT, RASA, etc.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "lEYOkzT7r8Pj"
      },
      "outputs": [],
      "source": [
        "# se desarrollara en futuras versiones"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_ibsChXBsNdX"
      },
      "source": [
        "## 3. Gestión del Diálogo\n",
        "\n",
        "___"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zEnB65VssQvq"
      },
      "source": [
        "### Módulo de Gestión de Estado:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Asignación de valores al diccionario de consulta\n",
        "consulta_dict['id_consulta'] = None  # ID de la consulta (aún no asignado)\n",
        "consulta_dict['id_cliente'] = None  # ID del cliente (aún no asignado)\n",
        "consulta_dict['formato_consulta'] = entrada_tipo  # Formato de la consulta (aún no especificado)\n",
        "consulta_dict['entrada_usuario'] = texto  # Transcripción del audio (aún no disponible)\n",
        "consulta_dict['entrada_lemas_filtrados'] = lemmas_filtrados  # Lemas filtrados de la entrada del usuario\n",
        "consulta_dict['dict_producto_indice_considencias'] = dict_count_coincidences  # Diccionario de productos y sus coincidencias\n",
        "consulta_dict['card_recomendacion'] = None  # Tarjeta de recomendación (aún no generada)\n",
        "audio_recomendacion = None  # Audio de la recomendación (aún no generado)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BByh2AXGsVmJ"
      },
      "source": [
        "### Motor de Respuesta:\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j15ewWSasb4F"
      },
      "source": [
        "Generación de Respuestas: Uso de los algoritmos predefinidos de clasificacion según las intenciones y preferencias detectadas.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Limpiando la columna 'Precio': eliminando el signo de dólar, eliminando los puntos del millar y reemplazando la coma decimal por un punto\n",
        "df_frutas_verduras['Precio'] = df_frutas_verduras['Precio'].apply(common_functions.limpiar_signo_peso)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [],
      "source": [
        "# DataFrame filtrado por columnas de interes\n",
        "df_productos_filtrados = df_frutas_verduras.loc[series_ordered_count_coincidences.index, ['Producto', 'Supermercado', 'Precio']]\n",
        "\n",
        "# Se comprueba si hay algun token con relacion los sinonimos de referencia\n",
        "# DataFrame filtrado, acortado y ordenado por precio\n",
        "if consulta_precio:\n",
        "    df_productos_filtrados = df_productos_filtrados.sort_values(by='Precio')\n",
        "    df_productos_filtrados = df_productos_filtrados[:5]\n",
        "else:\n",
        "    # DataFrame filtrado, acortado a 5 resultados\n",
        "    df_productos_filtrados = df_productos_filtrados[:5]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Diccionario para almacenar detalles de cada uno de los productos\n",
        "diccionario_productos_precio = {}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Inicialización de la recomendación\n",
        "recomendacion = \"Los productos recomendados basados en su consulta y características mencionadas son: \\n\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "UjnjzK3gseaL"
      },
      "outputs": [],
      "source": [
        "# Iterar sobre los productos filtrados y ordenados\n",
        "for count, (x, producto_filtrado_info) in enumerate(df_productos_filtrados.iterrows(), start=1):\n",
        "    # Añadir detalles del producto al diccionario\n",
        "    diccionario_productos_precio[x] = {\n",
        "        'Posicion': count,\n",
        "        'Producto': producto_filtrado_info['Producto'],\n",
        "        'Supermercado': producto_filtrado_info['Supermercado'],\n",
        "        'Precio': producto_filtrado_info['Precio']\n",
        "    }\n",
        "    # Añadir recomendación a la lista\n",
        "    recomendacion += f'\\n En la posición {count}: {producto_filtrado_info[\"Producto\"]} en {producto_filtrado_info[\"Supermercado\"]} a {producto_filtrado_info[\"Precio\"]} pesos'\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Redondear números en la recomendación (si es necesario)\n",
        "recomendacion = common_functions.redondear_numeros(recomendacion)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Asignar la recomendación al diccionario de consulta\n",
        "consulta_dict['card_recomendacion'] = recomendacion"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Los productos recomendados basados en su consulta y características mencionadas son: \\n\\n En la posición 1: Snack manzana roja deshidratada Frutty 18 g. en Carrefour a 535 pesos\\n En la posición 2: Pera roja x kg. en Carrefour a 2290 pesos\\n En la posición 3: Tomates secos 70 g. en Carrefour a 2229 pesos\\n En la posición 4: Snack manzana roja deshidratada Frutty 18 g. en Carrefour a 535 pesos\\n En la posición 5: Pera roja x kg. en Carrefour a 2290 pesos'"
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "consulta_dict['card_recomendacion']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QntMxU6_shpm"
      },
      "source": [
        "### Personalización y Contexto: Adaptar las respuestas en función del historial del usuario\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "MU_3as2dsi2S"
      },
      "outputs": [],
      "source": [
        "# se desarrollara en futuras versiones"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9-sSu2b0soDe"
      },
      "source": [
        "## 4. texto a voz\n",
        "\n",
        "___"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q5eR9QLTssCK"
      },
      "source": [
        "### Conversión de texto a Voz (TTS)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "kzi_CA2tswVF"
      },
      "outputs": [],
      "source": [
        "# google text to speech tomará la variable recomendacion como el texto a convertir en voz y establecerá el idioma como español ('es')\n",
        "tts = gTTS(text=recomendacion, lang='es')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Compresion en formato BytesIO"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Guardar el audio en un objeto BytesIO\n",
        "audio_buffer = io.BytesIO()\n",
        "tts.write_to_fp(audio_buffer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "execution_count": 41,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Asegurarse de que el puntero esté al principio del buffer\n",
        "audio_buffer.seek(0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Se guarda el audio de respuesta en el diccionario de la consulta\n",
        "consulta_dict['recomendacion_audio'] = audio_buffer"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
