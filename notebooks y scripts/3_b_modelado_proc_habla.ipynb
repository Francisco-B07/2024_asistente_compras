{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XTpu7pHup5pq"
      },
      "source": [
        "## **Estructura de sub-etapas del procesamiento del habla:**\n",
        "\n",
        "---\n",
        "\n",
        "```\n",
        "├── Input Layer\n",
        "│   ├── Audio Capture\n",
        "│   └── ASR (Speech-to-Text)\n",
        "├── NLP Layer\n",
        "│   ├── Text Preprocessing\n",
        "│   ├── Intent Detection\n",
        "│   ├── Entity Recognition\n",
        "│   └── Sentiment Analysis\n",
        "├── Dialogue Management\n",
        "│   ├── State Management\n",
        "│   ├── Response Generation\n",
        "│   ├── Response Selection\n",
        "│   └── Context Handling\n",
        "├── Output Layer\n",
        "│   ├── TTS (Text-to-Speech)\n",
        "│   └── Audio Playback\n",
        "\n",
        "```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ba_DUci1CkX6"
      },
      "source": [
        "### **Estructura operativa para cada sub-etapa:**\n",
        "\n",
        "**Selección de técnicas de modelado:** En este caso se utilizara [] para la etapa de reconocimiento de voz, [] para el procesamiento y analisis de texto y [] para la conversion de texto a voz.\n",
        "\n",
        "**Generación de un diseño de comprobación:** Para elegir el modelo correcto, este devera ser el que pondere mas alto en un promedio de las diferentes metricas de evaluacion del modelo.\n",
        "\n",
        "**Generación de los modelos:** Se definiran y configuraran los parametros del modelo para pasar a la etapa de ejecucion y descripcion.\n",
        "\n",
        "**Evaluación del modelo:** Se evaluaran los diferentes modelos de manera individual en busqueda de optimizar sus parametros y escoger la combinacion mas optima entre modelos / parametros individuales."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JM_Jd-w3lOWe"
      },
      "outputs": [],
      "source": [
        "# Execute if use colab and you need import files\n",
        "from google.colab import files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Execute if use colab and you need import files\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "oTkfaLx7boQi"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "zsh:1: command not found: apt-get\n",
            "zsh:1: command not found: apt-get\n",
            "zsh:1: command not found: apt-get\n"
          ]
        }
      ],
      "source": [
        "# Execute if use colab\n",
        "#%%bash\n",
        "!apt-get update\n",
        "!apt-get install python3\n",
        "!apt-get install -venv\n",
        "!python3 -m venv proc_habla\n",
        "!source proc_habla/bin/activate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create and activate virtual env for speech processing stage\n",
        "!python3 -m venv proc_habla\n",
        "!source proc_habla/bin/activate"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T0MT6XY2qoIA"
      },
      "source": [
        "## **1. Entrada de Usuario (Reconocimiento del Habla)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Librerias y paquetes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "yIsbz7_HkZZJ"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: SpeechRecognition in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (3.10.4)\n",
            "Requirement already satisfied: requests>=2.26.0 in /Users/cristianariel/Library/Python/3.11/lib/python/site-packages (from SpeechRecognition) (2.31.0)\n",
            "Requirement already satisfied: typing-extensions in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from SpeechRecognition) (4.8.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/cristianariel/Library/Python/3.11/lib/python/site-packages (from requests>=2.26.0->SpeechRecognition) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /Users/cristianariel/Library/Python/3.11/lib/python/site-packages (from requests>=2.26.0->SpeechRecognition) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/cristianariel/Library/Python/3.11/lib/python/site-packages (from requests>=2.26.0->SpeechRecognition) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /Users/cristianariel/Library/Python/3.11/lib/python/site-packages (from requests>=2.26.0->SpeechRecognition) (2023.7.22)\n",
            "Requirement already satisfied: sounddevice in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (0.4.7)\n",
            "Requirement already satisfied: CFFI>=1.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from sounddevice) (1.16.0)\n",
            "Requirement already satisfied: pycparser in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from CFFI>=1.0->sounddevice) (2.21)\n",
            "Requirement already satisfied: scipy in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (1.11.1)\n",
            "Requirement already satisfied: numpy<1.28.0,>=1.21.6 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from scipy) (1.25.2)\n",
            "Requirement already satisfied: pydub in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (0.25.1)\n",
            "Requirement already satisfied: pocketsphinx in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (5.0.3)\n",
            "Requirement already satisfied: sounddevice in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from pocketsphinx) (0.4.7)\n",
            "Requirement already satisfied: CFFI>=1.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from sounddevice->pocketsphinx) (1.16.0)\n",
            "Requirement already satisfied: pycparser in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from CFFI>=1.0->sounddevice->pocketsphinx) (2.21)\n"
          ]
        }
      ],
      "source": [
        "!pip3 install SpeechRecognition\n",
        "!pip3 install sounddevice\n",
        "!pip3 install scipy\n",
        "!pip3 install pydub\n",
        "!pip install pocketsphinx"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "eQgslv4y1nrF"
      },
      "outputs": [],
      "source": [
        "import speech_recognition as sr\n",
        "import numpy as np\n",
        "import wave\n",
        "import pandas as pd\n",
        "import sounddevice as sd\n",
        "from scipy.io.wavfile import write\n",
        "import queue\n",
        "import threading\n",
        "from pydub import AudioSegment\n",
        "import subprocess\n",
        "import zipfile\n",
        "import os\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Archivos descomprimidos en: /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/speech_recognition/pocketsphinx-data/es-ES/\n"
          ]
        }
      ],
      "source": [
        "# Ruta del archivo zip descargado\n",
        "ruta_modelo_comprimido_pocketsphinx_esp = \"../datos/brutos/modelos_proc_habla/modelo_esp.zip\"\n",
        "\n",
        "# Directorio donde se colocarán los archivos descomprimidos\n",
        "ruta_modelo_descomprimido_pocketsphinx_esp = \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/speech_recognition/pocketsphinx-data/es-ES/\"\n",
        "\n",
        "# Descomprimir el archivo zip\n",
        "with zipfile.ZipFile(ruta_modelo_comprimido_pocketsphinx_esp, 'r') as zip_ref:\n",
        "    zip_ref.extractall(ruta_modelo_descomprimido_pocketsphinx_esp)\n",
        "\n",
        "print(\"Archivos descomprimidos en:\", ruta_modelo_descomprimido_pocketsphinx_esp)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "sudo: a terminal is required to read the password; either use the -S option to read from standard input or configure an askpass helper\n",
            "sudo: a password is required\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "FFmpeg instalado exitosamente en sistemas basados en Debian.\n",
            "FFmpeg instalado exitosamente en macOS utilizando Homebrew.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Warning: ffmpeg 7.0.1 is already installed and up-to-date.\n",
            "To reinstall 7.0.1, run:\n",
            "  brew reinstall ffmpeg\n"
          ]
        }
      ],
      "source": [
        "try:\n",
        "    subprocess.run([\"sudo\", \"apt-get\", \"install\", \"ffmpeg\"])\n",
        "    print(\"FFmpeg instalado exitosamente en sistemas basados en Debian.\")\n",
        "except Exception as e:\n",
        "    print(\"Error al instalar FFmpeg:\", e)\n",
        "try:\n",
        "    subprocess.run([\"brew\", \"install\", \"ffmpeg\"])\n",
        "    print(\"FFmpeg instalado exitosamente en macOS utilizando Homebrew.\")\n",
        "except Exception as e:\n",
        "    print(\"Error al instalar FFmpeg:\", e)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### DataFrames"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "columns_consultas_df = ['id_consulta', 'id_cliente', 'formato_consulta', 'transcripción_audio', 'entrada_texto', 'productos_detectados']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "consultas_df = pd.DataFrame(columns=columns_consultas_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "path_csv_rutas_verduras = '../datos/procesaodos/VerdurasporSupermercado.csv'\n",
        "df_frutas_verduras = pd.read_csv(path_csv_rutas_verduras)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Supermercado</th>\n",
              "      <th>Producto</th>\n",
              "      <th>Precio</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Carrefour</td>\n",
              "      <td>Ajo suelto x kg.</td>\n",
              "      <td>$ 7.690,00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Carrefour</td>\n",
              "      <td>Tomate perita x kg.</td>\n",
              "      <td>$ 5.499,00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Carrefour</td>\n",
              "      <td>Sandía x kg.</td>\n",
              "      <td>$ 2.499,00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Carrefour</td>\n",
              "      <td>Rúcula x 1 atado</td>\n",
              "      <td>$ 699,00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Carrefour</td>\n",
              "      <td>Acelga x paquete</td>\n",
              "      <td>$ 1.189,00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Carrefour</td>\n",
              "      <td>Cebolla morada x kg.</td>\n",
              "      <td>$ 1.799,00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Carrefour</td>\n",
              "      <td>Lechuga morada kg.</td>\n",
              "      <td>$ 5.599,00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Carrefour</td>\n",
              "      <td>Lechuga francesa hidropónica 220 g.</td>\n",
              "      <td>$ 1.899,00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Carrefour</td>\n",
              "      <td>Lima taití x kg.</td>\n",
              "      <td>$ 2.999,00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Carrefour</td>\n",
              "      <td>Maní tostado pelado sin sal x kg.</td>\n",
              "      <td>$ 5.290,00</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  Supermercado                             Producto      Precio\n",
              "0    Carrefour                     Ajo suelto x kg.  $ 7.690,00\n",
              "1    Carrefour                  Tomate perita x kg.  $ 5.499,00\n",
              "2    Carrefour                         Sandía x kg.  $ 2.499,00\n",
              "3    Carrefour                     Rúcula x 1 atado    $ 699,00\n",
              "4    Carrefour                     Acelga x paquete  $ 1.189,00\n",
              "5    Carrefour                 Cebolla morada x kg.  $ 1.799,00\n",
              "6    Carrefour                   Lechuga morada kg.  $ 5.599,00\n",
              "7    Carrefour  Lechuga francesa hidropónica 220 g.  $ 1.899,00\n",
              "8    Carrefour                     Lima taití x kg.  $ 2.999,00\n",
              "9    Carrefour    Maní tostado pelado sin sal x kg.  $ 5.290,00"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_frutas_verduras.head(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mxPsnrV6riGR"
      },
      "source": [
        "## **1. Módulo de Captura de entradas por texto y audio:**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### a. Captura de entradas de texto"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Conexion con api de fast-api\n",
        "# aui iria la conexion con un script encargado de conectar con la api de fast-api"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "texto_prueba = 'estoy buscando tomates en oferta pero que esten bien rojitos :p'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### b. Captura de Audio"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "*Bugs*\n",
        "\n",
        "- [ ] verificar existencia de id_cliente, id_consulta y diccionario con respuesta dentro de dataframe ouput\n",
        "- [ ] Definir como se llamara a la funcion chatbot\n",
        "    - [ ] Definir el anidamiento de funciones, para que con solo llamar a chatbot, me entregue el resultado (lista de productos limpia)\n",
        "- [ ] Contar considencias de lemas consulta usuario por lemas en columnas productos_tokens_lemmas\n",
        "    - [ ] almacenar en un diccionario\n",
        "    - [ ] ordenrar diccionario por orden de mayor a menor considencia\n",
        "- [ ] text to speech\n",
        "- [ ] reconocimiento de voz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "8bLph4ehd_0_"
      },
      "outputs": [],
      "source": [
        "SAMPLE_RATE = 44100  # Tasa de muestreo\n",
        "DURATION = 10  # Duración de la grabación en segundos\n",
        "AUDIO_FILES_PATH = \"../datos/brutos/audios_proc_habla/\"\n",
        "FILENAME = \"output\"  # Nombre del archivo de salida\n",
        "EXTENCION_ENTRADA = '.wav'\n",
        "EXTENCION_SALIDA = '.aiff'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "ruta_audio_entrada = AUDIO_FILES_PATH + FILENAME + EXTENCION_ENTRADA\n",
        "ruta_audio_entrada_convertido = AUDIO_FILES_PATH + 'waw_conv_' + FILENAME + EXTENCION_SALIDA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "5W7StwLecqQV"
      },
      "outputs": [],
      "source": [
        "def record_audio(audio_file_path = AUDIO_FILES_PATH, filename = FILENAME, duration = DURATION, sample_rate = SAMPLE_RATE):\n",
        "    print(\"Grabando...\")\n",
        "    # Grabar audio con 1 canal (mono)\n",
        "    recording = sd.rec(int(duration * sample_rate), samplerate=sample_rate, channels=1)\n",
        "    sd.wait()  # Esperar a que termine la grabación\n",
        "    print(\"Grabación finalizada\")\n",
        "    write(ruta_audio_entrada, sample_rate, recording)\n",
        "    return filename"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [],
      "source": [
        "def convert_to_wav(input_file = ruta_audio_entrada, output_file = ruta_audio_entrada_convertido):\n",
        "    sound = AudioSegment.from_file(input_file)\n",
        "    sound.export(output_file, format=\"aiff\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [],
      "source": [
        "def chatbot():\n",
        "    record_audio()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "chatbot()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Uso de la función convert_to_wav\n",
        "convert_to_wav(ruta_audio_entrada, ruta_audio_entrada_convertido)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c6PxS_YcrlCZ"
      },
      "source": [
        "#### Reconocimiento del Habla (ASR - Automatic Speech Recognition):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YfbVSNU0m3N4"
      },
      "outputs": [],
      "source": [
        "# Crear un objeto Recognizer\n",
        "recognizer = sr.Recognizer()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def recognize_speech():\n",
        "    recognizer = sr.Recognizer()\n",
        "\n",
        "    try:\n",
        "        with sr.AudioFile(ruta_audio_entrada_convertido) as source:\n",
        "            audio_data = recognizer.record(source)\n",
        "            text = recognizer.recognize_sphinx(audio_data, language=\"es-ES\")\n",
        "            print(\"Texto reconocido:\", text)\n",
        "    except sr.UnknownValueError:\n",
        "        print(\"No se pudo entender el audio\")\n",
        "    except sr.RequestError as e:\n",
        "        print(\"Error al solicitar resultados de reconocimiento de voz; {0}\".format(e))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Ejecutar la función para reconocer el discurso\n",
        "recognize_speech()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xEwSWIZcp4zp"
      },
      "outputs": [],
      "source": [
        "# Abrir el archivo de audio\n",
        "def transcribe_audio(audio_lang = 'es-ES'):\n",
        "    with sr.AudioFile(ruta_audio_entrada_convertido) as source:\n",
        "        # Escuchar el audio (en inglés)\n",
        "        audio = recognizer.record(source)\n",
        "\n",
        "        # Utilizar Google Speech Recognition para transcribir el audio\n",
        "        try:\n",
        "            text = recognizer.recognize_google(audio, audio_lang)\n",
        "            print(\"Transcripción: \", text)\n",
        "            return text\n",
        "        except sr.UnknownValueError:\n",
        "            print(\"No se pudo entender el audio\")\n",
        "        except sr.RequestError as e:\n",
        "            print(\"Error al solicitar resultados del servicio Google Speech Recognition; {0}\".format(e))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sK32Iyq1Y7QR"
      },
      "outputs": [],
      "source": [
        "transcribe_audio()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pxpKQFiNm7m-"
      },
      "outputs": [],
      "source": [
        "# Transcribir y mostrar el resultado\n",
        "text = transcribe_audio(audio_file_path, audio_lang)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AcUSQzM7qsxY"
      },
      "source": [
        "## **2. Procesamiento del Lenguaje Natural (NLP)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: spacy in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (3.7.4)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from spacy) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from spacy) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from spacy) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from spacy) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from spacy) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from spacy) (8.2.3)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from spacy) (1.1.2)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from spacy) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from spacy) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.4.0,>=0.1.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from spacy) (0.3.4)\n",
            "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from spacy) (0.9.0)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from spacy) (6.4.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from spacy) (4.66.1)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /Users/cristianariel/Library/Python/3.11/lib/python/site-packages (from spacy) (2.31.0)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from spacy) (2.6.3)\n",
            "Requirement already satisfied: jinja2 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from spacy) (3.1.2)\n",
            "Requirement already satisfied: setuptools in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from spacy) (65.5.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /Users/cristianariel/Library/Python/3.11/lib/python/site-packages (from spacy) (23.1)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from spacy) (3.4.0)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from spacy) (1.25.2)\n",
            "Requirement already satisfied: language-data>=1.2 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from langcodes<4.0.0,>=3.2.0->spacy) (1.2.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.16.3 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.16.3)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.8.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/cristianariel/Library/Python/3.11/lib/python/site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /Users/cristianariel/Library/Python/3.11/lib/python/site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/cristianariel/Library/Python/3.11/lib/python/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /Users/cristianariel/Library/Python/3.11/lib/python/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2023.7.22)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from thinc<8.3.0,>=8.2.2->spacy) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from thinc<8.3.0,>=8.2.2->spacy) (0.1.4)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from typer<0.10.0,>=0.3.0->spacy) (8.1.7)\n",
            "Requirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from weasel<0.4.0,>=0.1.0->spacy) (0.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from jinja2->spacy) (2.1.3)\n",
            "Requirement already satisfied: marisa-trie>=0.7.7 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy) (1.1.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install spacy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting es-core-news-sm==3.7.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/es_core_news_sm-3.7.0/es_core_news_sm-3.7.0-py3-none-any.whl (12.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.9/12.9 MB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: spacy<3.8.0,>=3.7.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from es-core-news-sm==3.7.0) (3.7.4)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (8.2.3)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (1.1.2)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.4.0,>=0.1.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (0.3.4)\n",
            "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (0.9.0)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (6.4.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (4.66.1)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /Users/cristianariel/Library/Python/3.11/lib/python/site-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (2.31.0)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (2.6.3)\n",
            "Requirement already satisfied: jinja2 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (3.1.2)\n",
            "Requirement already satisfied: setuptools in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (65.5.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /Users/cristianariel/Library/Python/3.11/lib/python/site-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (23.1)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (3.4.0)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (1.25.2)\n",
            "Requirement already satisfied: language-data>=1.2 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (1.2.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.16.3 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (2.16.3)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (4.8.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/cristianariel/Library/Python/3.11/lib/python/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /Users/cristianariel/Library/Python/3.11/lib/python/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/cristianariel/Library/Python/3.11/lib/python/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /Users/cristianariel/Library/Python/3.11/lib/python/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (2023.7.22)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (0.1.4)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from typer<0.10.0,>=0.3.0->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (8.1.7)\n",
            "Requirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from weasel<0.4.0,>=0.1.0->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (0.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from jinja2->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (2.1.3)\n",
            "Requirement already satisfied: marisa-trie>=0.7.7 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (1.1.1)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('es_core_news_sm')\n"
          ]
        }
      ],
      "source": [
        "# Descargar el modelo de spaCy para español desde un Jupyter Notebook\n",
        "!python3 -m spacy download es_core_news_sm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [],
      "source": [
        "import spacy\n",
        "import re"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cargar el modelo de spaCy para español\n",
        "nlp = spacy.load(\"es_core_news_sm\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HDaWq5syqu6m"
      },
      "source": [
        "### **Preprocesamiento de Texto:**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Lista de abreviaturas y formas no abreviadas de unidades de medida de peso\n",
        "unidades_medida_peso = ['g', 'gr', 'kg', 'mg', 'µg', 't', 'lb', 'oz', 'cwt',\n",
        "                        'gramos', 'kilogramos', 'miligramos', 'microgramos',\n",
        "                        'toneladas', 'libras', 'onzas', 'quintales']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [],
      "source": [
        "def procesar_texto(texto):\n",
        "    texto = texto.lower()\n",
        "    texto = re.sub(r'[,\\.;:!\\-*#@$!+_%^&`~]', '', texto)\n",
        "    texto = re.sub(r'\\s+', ' ', texto)\n",
        "\n",
        "    thresgold = 1\n",
        "\n",
        "    doc = nlp(texto)\n",
        "\n",
        "    tokens = [token.text for token in doc]\n",
        "    stopwords = spacy.lang.es.stop_words.STOP_WORDS\n",
        "    filtered_tokens = [token.text for token in doc if token.text not in stopwords and token.pos_ in ('NOUN', 'ADJ', 'ADP') and len(token.text) > thresgold and token.text not in unidades_medida_peso]\n",
        "    lemmas = [token.lemma_ for token in doc if token.text in filtered_tokens]\n",
        "    pos_tags = [(token.text, token.pos_) for token in doc if token.text in filtered_tokens]\n",
        "\n",
        "    return {\n",
        "        \"tokens\": tokens,\n",
        "        \"lemmas\": lemmas,\n",
        "        \"filtered_tokens\": filtered_tokens,\n",
        "        \"pos_tags\": pos_tags,\n",
        "    }"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FLfTLCw2q8IM"
      },
      "source": [
        "\n",
        "**Normalización del texto (eliminación de ruido, corrección ortográfica, etc.)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "B6Br9PyerAkd"
      },
      "outputs": [],
      "source": [
        "texto_analizado = procesar_texto(texto_prueba)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vrKl19tGq9KJ"
      },
      "source": [
        "**Tokenización**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "f5IX1gghrBXD"
      },
      "outputs": [],
      "source": [
        "tokens = texto_analizado['tokens']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['estoy',\n",
              " 'buscando',\n",
              " 'tomates',\n",
              " 'en',\n",
              " 'oferta',\n",
              " 'pero',\n",
              " 'que',\n",
              " 'esten',\n",
              " 'bien',\n",
              " 'rojitos',\n",
              " 'p']"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tokens"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xVbV-FF5q-af"
      },
      "source": [
        "**Eliminación de stop words.**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "TY1ASrUnrB3I"
      },
      "outputs": [],
      "source": [
        "tokens_filtrados = texto_analizado['filtered_tokens']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['tomates', 'oferta', 'rojitos']"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tokens_filtrados"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lt4d5DQcq_xW"
      },
      "source": [
        "**Lematización y stemming**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "ZkAeKi67rCfu"
      },
      "outputs": [],
      "source": [
        "lemmas_filtrados = texto_analizado['lemmas']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['tomate', 'oferta', 'rojito']"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "lemmas_filtrados"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Etiquetado de estructuras gramaticales:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [],
      "source": [
        "pos_tags_filtrados = texto_analizado['pos_tags']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[('tomates', 'NOUN'), ('oferta', 'NOUN'), ('rojitos', 'ADJ')]"
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pos_tags_filtrados"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C9ZvYH9dq1GY"
      },
      "source": [
        "### **Análisis de Texto:**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Detectar presencia de palabras de productos lematizadas dentro de dataframe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_frutas_verduras['producto_tokens_lemmas'] = df_frutas_verduras['Producto'].apply(lambda x: procesar_texto(x)['lemmas'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0          [suelto]\n",
              "1          [perita]\n",
              "2                []\n",
              "3           [atado]\n",
              "4         [paquete]\n",
              "           ...     \n",
              "456         [marca]\n",
              "457    [energetico]\n",
              "458        [school]\n",
              "459    [patagonico]\n",
              "460      [tropical]\n",
              "Name: producto_tokens_lemmas, Length: 461, dtype: object"
            ]
          },
          "execution_count": 52,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_frutas_verduras['producto_tokens_lemmas']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {},
      "outputs": [],
      "source": [
        "lista = [(index, row) for index, row in df_frutas_verduras.iterrows()]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "pandas.core.series.Series"
            ]
          },
          "execution_count": 50,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "type(lista[1][1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {},
      "outputs": [],
      "source": [
        "dict_count_coincidences = {}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for index, row in df_frutas_verduras.iterrows():\n",
        "    for token_producto in row['producto_tokens_lemmas']:\n",
        "        if token_producto in lemmas_filtrados:\n",
        "            if token_producto not in dict_count_coincidences:\n",
        "                dict_count_coincidences[index] = 1\n",
        "            else:\n",
        "                dict_count_coincidences[index] += 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {},
      "outputs": [],
      "source": [
        "series_ordered_count_coincidences = pd.Series(dict_count_coincidences).sort_values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<bound method Series.sort_values of 29     1\n",
              "76     1\n",
              "89     1\n",
              "182    1\n",
              "271    1\n",
              "296    1\n",
              "308    1\n",
              "dtype: int64>"
            ]
          },
          "execution_count": 73,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "series_ordered_count_coincidences"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wSCEB3hpr2y6"
      },
      "source": [
        "Análisis de Sentimiento: Determinar la emoción o tono del texto.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QtrOgErkr4PD"
      },
      "outputs": [],
      "source": [
        "#para futuras versiones"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hzhTpz0qr4lW"
      },
      "source": [
        "Detección de Intenciones (Intent Detection): Identificar la intención del usuario utilizando modelos como BERT, GPT, RASA, etc.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lEYOkzT7r8Pj"
      },
      "outputs": [],
      "source": [
        "#para futuras versiones"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_ibsChXBsNdX"
      },
      "source": [
        "## **3. Gestión del Diálogo**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zEnB65VssQvq"
      },
      "source": [
        "### Módulo de Gestión de Estado:\n",
        "Llevar un registro del contexto y estado del diálogo para mantener conversaciones coherentes.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3ECriCX3sVWu"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BByh2AXGsVmJ"
      },
      "source": [
        "### Motor de Respuesta:\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j15ewWSasb4F"
      },
      "source": [
        "Generación de Respuestas: Utilizar modelos generativos (como GPT-3) o respuestas predefinidas según las intenciones y entidades detectadas.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UjnjzK3gseaL"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xgvv-ETKsenO"
      },
      "source": [
        "Selección de Respuestas: Elegir la mejor respuesta entre varias opciones generadas.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3t1AFBk2sf1P"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QntMxU6_shpm"
      },
      "source": [
        "### Personalización y Contexto: Adaptar las respuestas en función del historial del usuario y el contexto actual."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MU_3as2dsi2S"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9-sSu2b0soDe"
      },
      "source": [
        "## 4. Salida de Usuario (Text-to-Speech)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q5eR9QLTssCK"
      },
      "source": [
        "### Conversión de Texto a Voz (TTS): Utilizar servicios como Google Text-to-Speech, Amazon Polly, o frameworks como Tacotron para convertir el texto generado en voz.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kzi_CA2tswVF"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u3TVK99Wswe8"
      },
      "source": [
        "### Reproducción de Audio: Entregar la respuesta de voz al usuario."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TOKovFuVsyaD"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
