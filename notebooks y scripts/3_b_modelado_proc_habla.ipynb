{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# **Procesamiento del habla**\n",
        "\n",
        "Version 1.0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Funcionalidades desbloqueadas por version:\n",
        "\n",
        "*Version 1.0:*\n",
        "\n",
        "- Entrada de consulta para un producto por vez\n",
        "- Recomendacion para el cliente:\n",
        "    - Algoritmo de ordenamiento basado en preferencias del usuario (dentro de la estructura gramatical)\n",
        "    - Deteccion de precio\n",
        "    - Caracteristicas particulares del producto\n",
        "\n",
        "*Version 1.3*\n",
        "- Entrada de consulta para mas de un producto\n",
        "- Recomendaciones basadas en analisis de sentimiento"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XTpu7pHup5pq"
      },
      "source": [
        "## Estructura de sub-etapas\n",
        "\n",
        "---\n",
        "\n",
        "```\n",
        "├── Reconocimiento del lenguaje\n",
        "│   ├── Captura de texto\n",
        "│   └── Captura de audio\n",
        "├── Procesamiento del lenguaje\n",
        "│   ├── Preprocesamiento de texto\n",
        "│   └── Analisis de texto\n",
        "├── Gestion de respuesta\n",
        "│   ├── Gestion del estado\n",
        "│   ├── Motor de respuesta\n",
        "│   └── Personalizacion\n",
        "├── texto a voz\n",
        "│   └── Conversion texto a voz\n",
        "\n",
        "```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ba_DUci1CkX6"
      },
      "source": [
        "#### _Estructura operativa para cada sub-etapa:_\n",
        "\n",
        "Se utilizaran las siguientes principales librerias por etapas, speechrecognition para reconocimiento de voz, pydub para transcripcion a texto, spacy para el procesamiento y analisis de texto y Google Text-to-Speech para la conversion de texto a voz.\n",
        "\n",
        "Para la entrega de la recomendacion se tomaran los tokens lematizados (filtrados por adjetivos, sustantivos y proposiciones) de la entrada del usuario y de la columna de productos del dataframe, y se recorrera token por token entre cada una, para comprobar la similitud, entregando por ultimo, un diccionario con el indice del producto en la tabla original y el grado de considencia."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Librerias y paquetes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### *Entorno virtuales*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 184,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create and activate virtual env for speech processing stage\n",
        "!python3 -m venv proc_habla\n",
        "!source proc_habla/bin/activate"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### *Instalacion*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 185,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: sounddevice in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (0.4.7)\n",
            "Requirement already satisfied: CFFI>=1.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from sounddevice) (1.16.0)\n",
            "Requirement already satisfied: pycparser in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from CFFI>=1.0->sounddevice) (2.21)\n",
            "Requirement already satisfied: scipy in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (1.11.1)\n",
            "Requirement already satisfied: numpy<1.28.0,>=1.21.6 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from scipy) (1.25.2)\n",
            "Requirement already satisfied: pydub in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (0.25.1)\n",
            "Requirement already satisfied: pocketsphinx in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (5.0.3)\n",
            "Requirement already satisfied: sounddevice in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from pocketsphinx) (0.4.7)\n",
            "Requirement already satisfied: CFFI>=1.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from sounddevice->pocketsphinx) (1.16.0)\n",
            "Requirement already satisfied: pycparser in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from CFFI>=1.0->sounddevice->pocketsphinx) (2.21)\n",
            "Requirement already satisfied: SpeechRecognition in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (3.10.4)\n",
            "Requirement already satisfied: requests>=2.26.0 in /Users/cristianariel/Library/Python/3.11/lib/python/site-packages (from SpeechRecognition) (2.31.0)\n",
            "Requirement already satisfied: typing-extensions in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from SpeechRecognition) (4.8.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/cristianariel/Library/Python/3.11/lib/python/site-packages (from requests>=2.26.0->SpeechRecognition) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /Users/cristianariel/Library/Python/3.11/lib/python/site-packages (from requests>=2.26.0->SpeechRecognition) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/cristianariel/Library/Python/3.11/lib/python/site-packages (from requests>=2.26.0->SpeechRecognition) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /Users/cristianariel/Library/Python/3.11/lib/python/site-packages (from requests>=2.26.0->SpeechRecognition) (2023.7.22)\n",
            "Requirement already satisfied: pyaudio in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (0.2.14)\n",
            "Requirement already satisfied: gtts in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (2.5.1)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /Users/cristianariel/Library/Python/3.11/lib/python/site-packages (from gtts) (2.31.0)\n",
            "Requirement already satisfied: click<8.2,>=7.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from gtts) (8.1.7)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/cristianariel/Library/Python/3.11/lib/python/site-packages (from requests<3,>=2.27->gtts) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /Users/cristianariel/Library/Python/3.11/lib/python/site-packages (from requests<3,>=2.27->gtts) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/cristianariel/Library/Python/3.11/lib/python/site-packages (from requests<3,>=2.27->gtts) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /Users/cristianariel/Library/Python/3.11/lib/python/site-packages (from requests<3,>=2.27->gtts) (2023.7.22)\n",
            "Requirement already satisfied: spacy in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (3.7.4)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from spacy) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from spacy) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from spacy) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from spacy) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from spacy) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from spacy) (8.2.3)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from spacy) (1.1.2)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from spacy) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from spacy) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.4.0,>=0.1.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from spacy) (0.3.4)\n",
            "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from spacy) (0.9.0)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from spacy) (6.4.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from spacy) (4.66.1)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /Users/cristianariel/Library/Python/3.11/lib/python/site-packages (from spacy) (2.31.0)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from spacy) (2.6.3)\n",
            "Requirement already satisfied: jinja2 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from spacy) (3.1.2)\n",
            "Requirement already satisfied: setuptools in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from spacy) (65.5.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /Users/cristianariel/Library/Python/3.11/lib/python/site-packages (from spacy) (23.1)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from spacy) (3.4.0)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from spacy) (1.25.2)\n",
            "Requirement already satisfied: language-data>=1.2 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from langcodes<4.0.0,>=3.2.0->spacy) (1.2.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.16.3 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.16.3)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.8.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/cristianariel/Library/Python/3.11/lib/python/site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /Users/cristianariel/Library/Python/3.11/lib/python/site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/cristianariel/Library/Python/3.11/lib/python/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /Users/cristianariel/Library/Python/3.11/lib/python/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2023.7.22)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from thinc<8.3.0,>=8.2.2->spacy) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from thinc<8.3.0,>=8.2.2->spacy) (0.1.4)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from typer<0.10.0,>=0.3.0->spacy) (8.1.7)\n",
            "Requirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from weasel<0.4.0,>=0.1.0->spacy) (0.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from jinja2->spacy) (2.1.3)\n",
            "Requirement already satisfied: marisa-trie>=0.7.7 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy) (1.1.1)\n"
          ]
        }
      ],
      "source": [
        "# Librerias de preprocesamiento\n",
        "!pip3 install sounddevice\n",
        "!pip3 install scipy\n",
        "!pip3 install pydub\n",
        "\n",
        "# Librerias de reconocimiento de voz\n",
        "!pip3 install pocketsphinx\n",
        "!pip3 install SpeechRecognition\n",
        "!pip3 install pyaudio\n",
        "\n",
        "# Librerias de generacion de voz\n",
        "!pip3 install gtts\n",
        "# Librerias de analisis linguistico\n",
        "!pip3 install spacy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 186,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting es-core-news-sm==3.7.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/es_core_news_sm-3.7.0/es_core_news_sm-3.7.0-py3-none-any.whl (12.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.9/12.9 MB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: spacy<3.8.0,>=3.7.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from es-core-news-sm==3.7.0) (3.7.4)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (8.2.3)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (1.1.2)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.4.0,>=0.1.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (0.3.4)\n",
            "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (0.9.0)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (6.4.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (4.66.1)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /Users/cristianariel/Library/Python/3.11/lib/python/site-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (2.31.0)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (2.6.3)\n",
            "Requirement already satisfied: jinja2 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (3.1.2)\n",
            "Requirement already satisfied: setuptools in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (65.5.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /Users/cristianariel/Library/Python/3.11/lib/python/site-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (23.1)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (3.4.0)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (1.25.2)\n",
            "Requirement already satisfied: language-data>=1.2 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (1.2.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.16.3 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (2.16.3)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (4.8.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/cristianariel/Library/Python/3.11/lib/python/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /Users/cristianariel/Library/Python/3.11/lib/python/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/cristianariel/Library/Python/3.11/lib/python/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /Users/cristianariel/Library/Python/3.11/lib/python/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (2023.7.22)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (0.1.4)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from typer<0.10.0,>=0.3.0->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (8.1.7)\n",
            "Requirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from weasel<0.4.0,>=0.1.0->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (0.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from jinja2->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (2.1.3)\n",
            "Requirement already satisfied: marisa-trie>=0.7.7 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (1.1.1)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('es_core_news_sm')\n"
          ]
        }
      ],
      "source": [
        "!python3 -m spacy download es_core_news_sm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### *Importacion*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 187,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Librerías para reconocimiento de voz y procesamiento de audio\n",
        "import speech_recognition as sr\n",
        "import sounddevice as sd\n",
        "from scipy.io.wavfile import write\n",
        "import queue\n",
        "import threading\n",
        "from pydub import AudioSegment\n",
        "import pyaudio\n",
        "\n",
        "# Librerías para manipulación de archivos y compresión\n",
        "import wave\n",
        "import zipfile\n",
        "import os\n",
        "import subprocess\n",
        "import io\n",
        "\n",
        "# Librerías para procesamiento de datos y análisis\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import spacy\n",
        "import re\n",
        "\n",
        "# Librería para generación de voz\n",
        "from gtts import gTTS\n",
        "\n",
        "# Importación de funciones comunes a otros cuadernos\n",
        "from funciones_comunes import common_functions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Lectura de datos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 188,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Defino el diccionario donde se almacenara la informacion de entrada y salida de la consulta\n",
        "consulta_dict = {}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 189,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Lectura y almacenado del dataframe\n",
        "path_csv_rutas_verduras = '../datos/procesaodos/VerdurasporSupermercado.csv'\n",
        "df_frutas_verduras = pd.read_csv(path_csv_rutas_verduras)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T0MT6XY2qoIA"
      },
      "source": [
        "## 1. Reconocimiento del Habla\n",
        "\n",
        "___"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### a. Captura de entradas de texto"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 190,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Conexion con api de fast-api\n",
        "# aqui iria la conexion con un script encargado de conectar con la api de fast-api"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 191,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Funcion tentativa para recibir la entrada de texto desde fast-api\n",
        "\n",
        "def entrada_texto(texto):\n",
        "    texto = input('Ingresa brevemete el producto que deseas comprar y sus caracteristicas: ')\n",
        "    return texto"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### b. Captura de Audio"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c6PxS_YcrlCZ"
      },
      "source": [
        "#### Reconocimiento del Habla (ASR - Automatic Speech Recognition):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 202,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Por favor, habla ahora.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "'bien Vamos a ver ahí si lo tomo yo tendría que estar hablando Hablando Hablando Hablando Hablando Hablando Hablando Hablando Hablando Hablando Hablando Hablando Hablando no se tendría que tener tendrá que ir Hablando Hablando Hablando Hablando Hablando Hablando Hablando vuelvo a hablar sigo hablando'"
            ]
          },
          "execution_count": 202,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def entrada_voz():\n",
        "    recognizer = sr.Recognizer()\n",
        "    mic = sr.Microphone()\n",
        "\n",
        "    with mic as source:\n",
        "        recognizer.adjust_for_ambient_noise(source, duration=1)\n",
        "        # Ajuste de sensibilidad y tiempo de pausa\n",
        "        recognizer.energy_threshold = 300  # Ajustar según el entorno\n",
        "        recognizer.pause_threshold = 1.0  # Ajustar según necesidad\n",
        "        print(\"Por favor, habla ahora.\")\n",
        "        audio = recognizer.listen(source)\n",
        "        \n",
        "    try:\n",
        "        texto = recognizer.recognize_google(audio, language='es-ES')\n",
        "    except sr.UnknownValueError:\n",
        "        print(\"No se pudo entender el audio\")\n",
        "    except sr.RequestError as e:\n",
        "        print(\"Error al conectarse con el servicio de Google: {0}\".format(e))\n",
        "\n",
        "    return texto"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### c. Identificar tipo de entrada"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 203,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Por favor, habla ahora.\n"
          ]
        }
      ],
      "source": [
        "# Recibo un tipo de entrada especifico y segun eso tomo un tipo de entrada o otro\n",
        "\n",
        "entrada_tipo = 'audio'\n",
        "\n",
        "if entrada_tipo == 'audio':\n",
        "    texto = entrada_voz()\n",
        "elif entrada_tipo == 'texto':\n",
        "    texto = entrada_texto()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AcUSQzM7qsxY"
      },
      "source": [
        "## 2. Procesamiento del Lenguaje Natural\n",
        "\n",
        "___"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 204,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cargar el modelo de spaCy para español\n",
        "\n",
        "nlp = spacy.load(\"es_core_news_sm\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HDaWq5syqu6m"
      },
      "source": [
        "### Preprocesamiento de texto\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 196,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "\"\\n\\n# unidades_medida_peso = ['g', 'gr', 'kg', 'mg', 'µg', 't', 'lb', 'oz', 'cwt',\\n                        #'gramos', 'kilogramos', 'miligramos', 'microgramos',\\n                        #'toneladas', 'libras', 'onzas', 'quintales']\\n\\n\""
            ]
          },
          "execution_count": 196,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Lista de abreviaturas y formas no abreviadas de unidades de medida de peso\n",
        "'''\n",
        "\n",
        "# unidades_medida_peso = ['g', 'gr', 'kg', 'mg', 'µg', 't', 'lb', 'oz', 'cwt',\n",
        "                        #'gramos', 'kilogramos', 'miligramos', 'microgramos',\n",
        "                        #'toneladas', 'libras', 'onzas', 'quintales']\n",
        "\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 205,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Funcion encargada de procesar texto\n",
        "\n",
        "def procesar_texto(texto):\n",
        "    texto = texto.lower()\n",
        "    texto = re.sub(r'[,\\.;:!\\-*#@$!+_%^&`~]', '', texto)\n",
        "    texto = re.sub(r'\\s+', ' ', texto)\n",
        "\n",
        "    thresgold = 1\n",
        "\n",
        "    doc = nlp(texto)\n",
        "\n",
        "    tokens = [token.texto for token in doc]\n",
        "    stopwords = spacy.lang.es.stop_words.STOP_WORDS\n",
        "    filtered_tokens = [\n",
        "        token.texto for token in doc\n",
        "        if token.texto not in stopwords\n",
        "        and token.pos_ in ('NOUN', 'ADJ', 'ADP')\n",
        "        and len(token.texto) > thresgold\n",
        "        ]#and token.texto not in unidades_medida_peso\n",
        "    lemmas = [token.lemma_ for token in doc if token.texto in filtered_tokens]\n",
        "    pos_tags = [(token.texto, token.pos_) for token in doc if token.texto in filtered_tokens]\n",
        "\n",
        "    return {\n",
        "        \"tokens\": tokens,\n",
        "        \"lemmas\": lemmas,\n",
        "        \"filtered_tokens\": filtered_tokens,\n",
        "        \"pos_tags\": pos_tags,\n",
        "    }"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FLfTLCw2q8IM"
      },
      "source": [
        "\n",
        "**Normalización del texto (eliminación de ruido, corrección ortográfica, etc.)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 208,
      "metadata": {
        "id": "B6Br9PyerAkd"
      },
      "outputs": [
        {
          "ename": "AttributeError",
          "evalue": "'spacy.tokens.token.Token' object has no attribute 'texto'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[208], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# texto analizado\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m texto_analizado \u001b[38;5;241m=\u001b[39m \u001b[43mprocesar_texto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtexto\u001b[49m\u001b[43m)\u001b[49m\n",
            "Cell \u001b[0;32mIn[205], line 12\u001b[0m, in \u001b[0;36mprocesar_texto\u001b[0;34m(texto)\u001b[0m\n\u001b[1;32m      8\u001b[0m thresgold \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     10\u001b[0m doc \u001b[38;5;241m=\u001b[39m nlp(texto)\n\u001b[0;32m---> 12\u001b[0m tokens \u001b[38;5;241m=\u001b[39m \u001b[43m[\u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtexto\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdoc\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     13\u001b[0m stopwords \u001b[38;5;241m=\u001b[39m spacy\u001b[38;5;241m.\u001b[39mlang\u001b[38;5;241m.\u001b[39mes\u001b[38;5;241m.\u001b[39mstop_words\u001b[38;5;241m.\u001b[39mSTOP_WORDS\n\u001b[1;32m     14\u001b[0m filtered_tokens \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     15\u001b[0m     token\u001b[38;5;241m.\u001b[39mtexto \u001b[38;5;28;01mfor\u001b[39;00m token \u001b[38;5;129;01min\u001b[39;00m doc\n\u001b[1;32m     16\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m token\u001b[38;5;241m.\u001b[39mtexto \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m stopwords\n\u001b[1;32m     17\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m token\u001b[38;5;241m.\u001b[39mpos_ \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNOUN\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mADJ\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mADP\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     18\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(token\u001b[38;5;241m.\u001b[39mtexto) \u001b[38;5;241m>\u001b[39m thresgold\n\u001b[1;32m     19\u001b[0m     ]\u001b[38;5;66;03m#and token.texto not in unidades_medida_peso\u001b[39;00m\n",
            "Cell \u001b[0;32mIn[205], line 12\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      8\u001b[0m thresgold \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     10\u001b[0m doc \u001b[38;5;241m=\u001b[39m nlp(texto)\n\u001b[0;32m---> 12\u001b[0m tokens \u001b[38;5;241m=\u001b[39m [\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtexto\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m token \u001b[38;5;129;01min\u001b[39;00m doc]\n\u001b[1;32m     13\u001b[0m stopwords \u001b[38;5;241m=\u001b[39m spacy\u001b[38;5;241m.\u001b[39mlang\u001b[38;5;241m.\u001b[39mes\u001b[38;5;241m.\u001b[39mstop_words\u001b[38;5;241m.\u001b[39mSTOP_WORDS\n\u001b[1;32m     14\u001b[0m filtered_tokens \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     15\u001b[0m     token\u001b[38;5;241m.\u001b[39mtexto \u001b[38;5;28;01mfor\u001b[39;00m token \u001b[38;5;129;01min\u001b[39;00m doc\n\u001b[1;32m     16\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m token\u001b[38;5;241m.\u001b[39mtexto \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m stopwords\n\u001b[1;32m     17\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m token\u001b[38;5;241m.\u001b[39mpos_ \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNOUN\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mADJ\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mADP\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     18\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(token\u001b[38;5;241m.\u001b[39mtexto) \u001b[38;5;241m>\u001b[39m thresgold\n\u001b[1;32m     19\u001b[0m     ]\u001b[38;5;66;03m#and token.texto not in unidades_medida_peso\u001b[39;00m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'spacy.tokens.token.Token' object has no attribute 'texto'"
          ]
        }
      ],
      "source": [
        "# texto analizado\n",
        "\n",
        "texto_analizado = procesar_texto(texto)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vrKl19tGq9KJ"
      },
      "source": [
        "**Tokenización**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f5IX1gghrBXD"
      },
      "outputs": [],
      "source": [
        "# tokens del texto analizado\n",
        "\n",
        "tokens = texto_analizado['tokens']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xVbV-FF5q-af"
      },
      "source": [
        "**Eliminación de stop words.**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TY1ASrUnrB3I"
      },
      "outputs": [],
      "source": [
        "# Tokens filtrados\n",
        "\n",
        "tokens_filtrados = texto_analizado['filtered_tokens']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lt4d5DQcq_xW"
      },
      "source": [
        "**Lematización y stemming**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZkAeKi67rCfu"
      },
      "outputs": [],
      "source": [
        "# lemas de tokens filtrados\n",
        "\n",
        "lemmas_filtrados = texto_analizado['lemmas']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Etiquetado de estructuras gramaticales:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# etiquetas gramaticales de los tokens filtrados\n",
        "\n",
        "pos_tags_filtrados = texto_analizado['pos_tags']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C9ZvYH9dq1GY"
      },
      "source": [
        "### Análisis de texto\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Detectar presencia de palabras de productos lematizadas dentro de dataframe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# carga del conjunto de datos en dataframe\n",
        "\n",
        "df_frutas_verduras['producto_tokens_lemmas'] = df_frutas_verduras['Producto'].apply(lambda x: procesar_texto(x)['lemmas'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# diccionario de considencias entre tokens lematizados de la columna y la entrada del usuario\n",
        "\n",
        "dict_count_coincidences = {}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# algoritmo para contar considencias entre tokens lematizados de la entrada del usuario y la columna/fila del dataframe\n",
        "\n",
        "for index, row in df_frutas_verduras.iterrows():\n",
        "    for token_producto in row['producto_tokens_lemmas']:\n",
        "        if token_producto in lemmas_filtrados:\n",
        "            if token_producto not in dict_count_coincidences:\n",
        "                dict_count_coincidences[index] = 1\n",
        "            else:\n",
        "                dict_count_coincidences[index] += 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Se transforma el diccionario a una seria de python para luego poder ordenarla por valor\n",
        "series_ordered_count_coincidences = pd.Series(dict_count_coincidences)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wSCEB3hpr2y6"
      },
      "source": [
        "Análisis de Sentimiento: Determinar la emoción o tono del texto.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QtrOgErkr4PD"
      },
      "outputs": [],
      "source": [
        "#para futuras versiones"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hzhTpz0qr4lW"
      },
      "source": [
        "Detección de Intenciones (Intent Detection): Identificar la intención del usuario utilizando modelos como BERT, GPT, RASA, etc.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lEYOkzT7r8Pj"
      },
      "outputs": [],
      "source": [
        "# para futuras versiones"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_ibsChXBsNdX"
      },
      "source": [
        "## 3. Gestión del Diálogo\n",
        "\n",
        "___"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zEnB65VssQvq"
      },
      "source": [
        "### Módulo de Gestión de Estado:\n",
        "Llevar un registro del contexto y estado del diálogo para mantener conversaciones coherentes.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "consulta_dict['id_consulta'] = None\n",
        "consulta_dict['id_cliente'] = None\n",
        "consulta_dict['formato_consulta'] = None\n",
        "consulta_dict['transcripción_audio'] = None\n",
        "consulta_dict['entrada_texto'] = texto\n",
        "consulta_dict['entrada_lemas_filtrados'] = lemmas_filtrados\n",
        "consulta_dict['dict_producto_indice_considencias'] = dict_count_coincidences\n",
        "consulta_dict['card_recomendacion'] = None\n",
        "audio_recomendacion = None"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BByh2AXGsVmJ"
      },
      "source": [
        "### Motor de Respuesta:\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j15ewWSasb4F"
      },
      "source": [
        "Generación de Respuestas: Utilizar modelos generativos (como GPT-3) o respuestas predefinidas según las intenciones y entidades detectadas.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# limpiando columna 'Precio' sacando signo de dolar y borrando los puntos del mil y remplazando la coma decimal por un punto\n",
        "\n",
        "df_frutas_verduras['Precio'] = df_frutas_verduras['Precio'].apply(common_functions.limpiar_signo_peso)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UjnjzK3gseaL"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Los productos recomendados en base a su consulta y caracteristicas mensionadas son:\n",
            "En el lugar 1: Tomates secos 70 g. en Carrefour a 2229 pesos\n",
            "En el lugar 2: Tomate seco 100 g. en Carrefour a 1799 pesos\n",
            "En el lugar 3: Tomates secos 70 g. en Carrefour a 2229 pesos\n",
            "En el lugar 4: Tomates Secos El Peoncito x 100 g. en La Anonima a 799 pesos\n",
            "En el lugar 5: Tomates Peritas Deshidratados Nature Food x 150 g. en La Anonima a 4750 pesos\n",
            "En el lugar 6: Tomates Deshidratados El Peoncito x 100 g. en La Anonima a 2150 pesos\n",
            "En el lugar 7: Tomates Secos El Peoncito x 100 g. en La Anonima a 4000 pesos\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Asegúrate de que series_ordered_count_coincidences es una Serie ordenada\n",
        "\n",
        "series_ordered_count_coincidences = series_ordered_count_coincidences.sort_values(ascending=False)\n",
        "\n",
        "# Inicialización de la recomendación\n",
        "recomendacion = 'Los productos recomendados en base a su consulta y caracteristicas mensionadas son:\\n'\n",
        "\n",
        "# Lista para almacenar las recomendaciones\n",
        "lista_string_reco_supers_prods = []\n",
        "\n",
        "# Iterar sobre los índices de las coincidencias ordenadas\n",
        "for count, x in enumerate(series_ordered_count_coincidences.index, start=1):\n",
        "    # Extraer los detalles del producto usando el índice\n",
        "    producto, supermercado, precio = df_frutas_verduras.loc[x, ['Producto', 'Supermercado', 'Precio']]\n",
        "    \n",
        "    # Añadir la recomendación a la lista\n",
        "    lista_string_reco_supers_prods.append(f'En el lugar {count}: {producto} en {supermercado} a {precio} pesos\\n')\n",
        "\n",
        "# Concatenar todas las recomendaciones en un solo string\n",
        "recomendacion += ''.join(lista_string_reco_supers_prods)\n",
        "\n",
        "recomendacion = common_functions.redondear_numeros(recomendacion)\n",
        "\n",
        "consulta_dict['card_recomendacion'] = recomendacion"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xgvv-ETKsenO"
      },
      "source": [
        "Selección de Respuestas: Elegir la mejor respuesta entre varias opciones generadas.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3t1AFBk2sf1P"
      },
      "outputs": [],
      "source": [
        "# Para proximas versiones"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QntMxU6_shpm"
      },
      "source": [
        "### Personalización y Contexto: Adaptar las respuestas en función del historial del usuario y el contexto actual."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MU_3as2dsi2S"
      },
      "outputs": [],
      "source": [
        "# Para proximas versiones"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9-sSu2b0soDe"
      },
      "source": [
        "## 4. texto a voz\n",
        "\n",
        "___"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q5eR9QLTssCK"
      },
      "source": [
        "### Conversión de texto a Voz (TTS): Utilizar servicios como Gogle texto-to-Speech, Amazon Polly, o frameworks como Tacotron para convertir el texto generado en voz.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kzi_CA2tswVF"
      },
      "outputs": [],
      "source": [
        "tts = gTTS(texto=recomendacion, lang='es')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Guardar el audio en un objeto BytesIO\n",
        "audio_buffer = io.BytesIO()\n",
        "tts.write_to_fp(audio_buffer)\n",
        "\n",
        "# Asegurarse de que el puntero esté al principio del buffer\n",
        "audio_buffer.seek(0)\n",
        "\n",
        "# Crear un diccionario y guardar el audio en él\n",
        "consulta_dict = {'recomendacion_audio': audio_buffer}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Funciones separadas para las primeras etapas de reconocimiento del habla: audio, texto\n",
        "def texto(texto):\n",
        "    "
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
