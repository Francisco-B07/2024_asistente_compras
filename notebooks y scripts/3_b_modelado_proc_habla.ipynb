{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# **Procesamiento del habla**\n",
        "\n",
        "Version 1.0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Funcionalidades desbloqueadas por version:\n",
        "\n",
        "*Version 1.0:*\n",
        "\n",
        "- Entrada de consulta para un producto por vez\n",
        "- Recomendacion para el cliente:\n",
        "    - Algoritmo de ordenamiento basado en preferencias del usuario (dentro de la estructura gramatical)\n",
        "    - Deteccion de precio\n",
        "    - Caracteristicas particulares del producto\n",
        "\n",
        "*Version 1.3*\n",
        "- Entrada de consulta para mas de un producto\n",
        "- Recomendaciones basadas en analisis de sentimiento"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XTpu7pHup5pq"
      },
      "source": [
        "## Estructura de sub-etapas\n",
        "\n",
        "---\n",
        "\n",
        "```\n",
        "├── Reconocimiento del lenguaje\n",
        "│   ├── Captura de texto\n",
        "│   └── Captura de audio\n",
        "├── Procesamiento del lenguaje\n",
        "│   ├── Preprocesamiento de texto\n",
        "│   └── Analisis de texto\n",
        "├── Gestion de respuesta\n",
        "│   ├── Gestion del estado\n",
        "│   ├── Motor de respuesta\n",
        "│   └── Personalizacion\n",
        "├── texto a voz\n",
        "│   └── Conversion texto a voz\n",
        "\n",
        "```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ba_DUci1CkX6"
      },
      "source": [
        "#### _Estructura operativa para cada sub-etapa:_\n",
        "\n",
        "Se utilizaran las siguientes principales librerias por etapas, speechrecognition para reconocimiento de voz, pydub para transcripcion a texto, spacy para el procesamiento y analisis de texto y Google Text-to-Speech para la conversion de texto a voz.\n",
        "\n",
        "Para la entrega de la recomendacion se tomaran los tokens lematizados (filtrados por adjetivos, sustantivos y proposiciones) de la entrada del usuario y de la columna de productos del dataframe, y se recorrera token por token entre cada una, para comprobar la similitud, entregando por ultimo, un diccionario con el indice del producto en la tabla original y el grado de considencia."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Librerias y paquetes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### *Entorno virtuales*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 149,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create and activate virtual env for speech processing stage\n",
        "!python3 -m venv proc_habla\n",
        "!source proc_habla/bin/activate"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### *Instalacion*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 150,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: sounddevice in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (0.4.7)\n",
            "Requirement already satisfied: CFFI>=1.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from sounddevice) (1.16.0)\n",
            "Requirement already satisfied: pycparser in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from CFFI>=1.0->sounddevice) (2.21)\n",
            "Requirement already satisfied: scipy in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (1.11.1)\n",
            "Requirement already satisfied: numpy<1.28.0,>=1.21.6 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from scipy) (1.25.2)\n",
            "Requirement already satisfied: pydub in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (0.25.1)\n",
            "Requirement already satisfied: pocketsphinx in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (5.0.3)\n",
            "Requirement already satisfied: sounddevice in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from pocketsphinx) (0.4.7)\n",
            "Requirement already satisfied: CFFI>=1.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from sounddevice->pocketsphinx) (1.16.0)\n",
            "Requirement already satisfied: pycparser in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from CFFI>=1.0->sounddevice->pocketsphinx) (2.21)\n",
            "Requirement already satisfied: SpeechRecognition in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (3.10.4)\n",
            "Requirement already satisfied: requests>=2.26.0 in /Users/cristianariel/Library/Python/3.11/lib/python/site-packages (from SpeechRecognition) (2.31.0)\n",
            "Requirement already satisfied: typing-extensions in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from SpeechRecognition) (4.8.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/cristianariel/Library/Python/3.11/lib/python/site-packages (from requests>=2.26.0->SpeechRecognition) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /Users/cristianariel/Library/Python/3.11/lib/python/site-packages (from requests>=2.26.0->SpeechRecognition) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/cristianariel/Library/Python/3.11/lib/python/site-packages (from requests>=2.26.0->SpeechRecognition) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /Users/cristianariel/Library/Python/3.11/lib/python/site-packages (from requests>=2.26.0->SpeechRecognition) (2023.7.22)\n",
            "Requirement already satisfied: gtts in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (2.5.1)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /Users/cristianariel/Library/Python/3.11/lib/python/site-packages (from gtts) (2.31.0)\n",
            "Requirement already satisfied: click<8.2,>=7.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from gtts) (8.1.7)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/cristianariel/Library/Python/3.11/lib/python/site-packages (from requests<3,>=2.27->gtts) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /Users/cristianariel/Library/Python/3.11/lib/python/site-packages (from requests<3,>=2.27->gtts) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/cristianariel/Library/Python/3.11/lib/python/site-packages (from requests<3,>=2.27->gtts) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /Users/cristianariel/Library/Python/3.11/lib/python/site-packages (from requests<3,>=2.27->gtts) (2023.7.22)\n",
            "Requirement already satisfied: spacy in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (3.7.4)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from spacy) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from spacy) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from spacy) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from spacy) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from spacy) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from spacy) (8.2.3)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from spacy) (1.1.2)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from spacy) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from spacy) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.4.0,>=0.1.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from spacy) (0.3.4)\n",
            "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from spacy) (0.9.0)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from spacy) (6.4.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from spacy) (4.66.1)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /Users/cristianariel/Library/Python/3.11/lib/python/site-packages (from spacy) (2.31.0)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from spacy) (2.6.3)\n",
            "Requirement already satisfied: jinja2 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from spacy) (3.1.2)\n",
            "Requirement already satisfied: setuptools in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from spacy) (65.5.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /Users/cristianariel/Library/Python/3.11/lib/python/site-packages (from spacy) (23.1)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from spacy) (3.4.0)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from spacy) (1.25.2)\n",
            "Requirement already satisfied: language-data>=1.2 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from langcodes<4.0.0,>=3.2.0->spacy) (1.2.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.16.3 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.16.3)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.8.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/cristianariel/Library/Python/3.11/lib/python/site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /Users/cristianariel/Library/Python/3.11/lib/python/site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/cristianariel/Library/Python/3.11/lib/python/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /Users/cristianariel/Library/Python/3.11/lib/python/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2023.7.22)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from thinc<8.3.0,>=8.2.2->spacy) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from thinc<8.3.0,>=8.2.2->spacy) (0.1.4)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from typer<0.10.0,>=0.3.0->spacy) (8.1.7)\n",
            "Requirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from weasel<0.4.0,>=0.1.0->spacy) (0.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from jinja2->spacy) (2.1.3)\n",
            "Requirement already satisfied: marisa-trie>=0.7.7 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy) (1.1.1)\n"
          ]
        }
      ],
      "source": [
        "# Librerias de preprocesamiento\n",
        "!pip3 install sounddevice\n",
        "!pip3 install scipy\n",
        "!pip3 install pydub\n",
        "\n",
        "# Librerias de reconocimiento de voz\n",
        "!pip3 install pocketsphinx\n",
        "!pip3 install SpeechRecognition\n",
        "\n",
        "# Librerias de generacion de voz\n",
        "!pip3 install gtts\n",
        "# Librerias de analisis linguistico\n",
        "!pip3 install spacy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 151,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting es-core-news-sm==3.7.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/es_core_news_sm-3.7.0/es_core_news_sm-3.7.0-py3-none-any.whl (12.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.9/12.9 MB\u001b[0m \u001b[31m691.7 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: spacy<3.8.0,>=3.7.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from es-core-news-sm==3.7.0) (3.7.4)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (8.2.3)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (1.1.2)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.4.0,>=0.1.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (0.3.4)\n",
            "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (0.9.0)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (6.4.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (4.66.1)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /Users/cristianariel/Library/Python/3.11/lib/python/site-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (2.31.0)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (2.6.3)\n",
            "Requirement already satisfied: jinja2 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (3.1.2)\n",
            "Requirement already satisfied: setuptools in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (65.5.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /Users/cristianariel/Library/Python/3.11/lib/python/site-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (23.1)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (3.4.0)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (1.25.2)\n",
            "Requirement already satisfied: language-data>=1.2 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (1.2.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.16.3 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (2.16.3)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (4.8.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/cristianariel/Library/Python/3.11/lib/python/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /Users/cristianariel/Library/Python/3.11/lib/python/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/cristianariel/Library/Python/3.11/lib/python/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /Users/cristianariel/Library/Python/3.11/lib/python/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (2023.7.22)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (0.1.4)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from typer<0.10.0,>=0.3.0->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (8.1.7)\n",
            "Requirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from weasel<0.4.0,>=0.1.0->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (0.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from jinja2->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (2.1.3)\n",
            "Requirement already satisfied: marisa-trie>=0.7.7 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (1.1.1)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('es_core_news_sm')\n"
          ]
        }
      ],
      "source": [
        "!python3 -m spacy download es_core_news_sm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### *Importacion*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 152,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Librerías para reconocimiento de voz y procesamiento de audio\n",
        "import speech_recognition as sr\n",
        "import sounddevice as sd\n",
        "from scipy.io.wavfile import write\n",
        "import queue\n",
        "import threading\n",
        "from pydub import AudioSegment\n",
        "\n",
        "# Librerías para manipulación de archivos y compresión\n",
        "import wave\n",
        "import zipfile\n",
        "import os\n",
        "import subprocess\n",
        "import io\n",
        "\n",
        "# Librerías para procesamiento de datos y análisis\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import spacy\n",
        "import re\n",
        "\n",
        "# Librería para generación de voz\n",
        "from gtts import gTTS\n",
        "\n",
        "# Importación de funciones comunes a otros cuadernos\n",
        "from funciones_comunes import common_functions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Lectura de datos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 153,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Defino el diccionario donde se almacenara la informacion de entrada y salida de la consulta\n",
        "consulta_dict = {}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 154,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Lectura y almacenado del dataframe\n",
        "path_csv_rutas_verduras = '../datos/procesaodos/VerdurasporSupermercado.csv'\n",
        "df_frutas_verduras = pd.read_csv(path_csv_rutas_verduras)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T0MT6XY2qoIA"
      },
      "source": [
        "## 1. Reconocimiento del Habla\n",
        "\n",
        "___"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### a. Captura de entradas de texto"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 155,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Conexion con api de fast-api\n",
        "# aqui iria la conexion con un script encargado de conectar con la api de fast-api"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 156,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Funcion tentativa para recibir la entrada de texto desde fast-api\n",
        "\n",
        "def entrada_texto(texto):\n",
        "    texto = input('Ingresa brevemete el producto que deseas comprar y sus caracteristicas: ')\n",
        "    return texto"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### b. Captura de Audio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 157,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Archivos descomprimidos en: /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/speech_recognition/pocketsphinx-data/es-ES/\n"
          ]
        }
      ],
      "source": [
        "# Ruta del archivo zip descargado del modelo de pydub\n",
        "ruta_modelo_comprimido_pocketsphinx_esp = \"../datos/brutos/modelos_proc_habla/modelo_esp.zip\"\n",
        "\n",
        "# Directorio donde se colocarán los archivos descomprimidos del modelo en español de pydub\n",
        "ruta_modelo_descomprimido_pocketsphinx_esp = \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/speech_recognition/pocketsphinx-data/es-ES/\"\n",
        "\n",
        "# Descomprimir el archivo zip\n",
        "with zipfile.ZipFile(ruta_modelo_comprimido_pocketsphinx_esp, 'r') as zip_ref:\n",
        "    zip_ref.extractall(ruta_modelo_descomprimido_pocketsphinx_esp)\n",
        "\n",
        "print(\"Archivos descomprimidos en:\", ruta_modelo_descomprimido_pocketsphinx_esp)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 158,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "sudo: a terminal is required to read the password; either use the -S option to read from standard input or configure an askpass helper\n",
            "sudo: a password is required\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "FFmpeg instalado exitosamente en sistemas basados en Debian.\n",
            "FFmpeg instalado exitosamente en macOS utilizando Homebrew.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Warning: ffmpeg 7.0.1 is already installed and up-to-date.\n",
            "To reinstall 7.0.1, run:\n",
            "  brew reinstall ffmpeg\n"
          ]
        }
      ],
      "source": [
        "# instalacion de conversor de audio a formatos compatibles para librerias de transcripcion del texto\n",
        "\n",
        "try:\n",
        "    subprocess.run([\"sudo\", \"apt-get\", \"install\", \"ffmpeg\"])\n",
        "    print(\"FFmpeg instalado exitosamente en sistemas basados en Debian.\")\n",
        "except Exception as e:\n",
        "    print(\"Error al instalar FFmpeg:\", e)\n",
        "try:\n",
        "    subprocess.run([\"brew\", \"install\", \"ffmpeg\"])\n",
        "    print(\"FFmpeg instalado exitosamente en macOS utilizando Homebrew.\")\n",
        "except Exception as e:\n",
        "    print(\"Error al instalar FFmpeg:\", e)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 159,
      "metadata": {
        "id": "8bLph4ehd_0_"
      },
      "outputs": [],
      "source": [
        "# Parametros para la grabacion del audio de entrada\n",
        "SAMPLE_RATE = 44100  # Tasa de muestreo\n",
        "DURATION = 10 # Duración de la grabación en segundos\n",
        "AUDIO_FILES_PATH = \"../datos/brutos/audios_proc_habla/\" # direccion local del audio grabado\n",
        "FILENAME = \"output\"  # Nombre del archivo de salida\n",
        "EXTENCION_ENTRADA = '.wav' # extension de entrada del audio grabado\n",
        "ruta_audio_entrada = AUDIO_FILES_PATH + FILENAME + EXTENCION_ENTRADA # ruta de entrada del audio grabado\n",
        "\n",
        "# Parametros para la conversion del audio\n",
        "EXTENCION_SALIDA = '.aiff' # extension de salida del audio tras convertir\n",
        "ruta_audio_entrada_convertido = AUDIO_FILES_PATH + 'waw_conv_' + FILENAME + EXTENCION_SALIDA # ruta donde se almacenara el audio convertido"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 160,
      "metadata": {
        "id": "5W7StwLecqQV"
      },
      "outputs": [],
      "source": [
        "def record_audio(audio_file_path = AUDIO_FILES_PATH, filename = FILENAME, duration = DURATION, sample_rate = SAMPLE_RATE):\n",
        "    # Grabacion de audio con 1 canal\n",
        "    recording = sd.rec(int(duration * sample_rate), samplerate=sample_rate, channels=1)\n",
        "    sd.wait()  # Esperar a que termine la grabación\n",
        "    write(ruta_audio_entrada, sample_rate, recording)\n",
        "    return filename"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 161,
      "metadata": {},
      "outputs": [],
      "source": [
        "def convert_to_wav(input_file = ruta_audio_entrada, output_file = ruta_audio_entrada_convertido):\n",
        "    sound = AudioSegment.from_file(input_file)\n",
        "    sound.export(output_file, format=\"aiff\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c6PxS_YcrlCZ"
      },
      "source": [
        "#### Reconocimiento del Habla (ASR - Automatic Speech Recognition):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 162,
      "metadata": {
        "id": "YfbVSNU0m3N4"
      },
      "outputs": [],
      "source": [
        "recognizer = sr.Recognizer()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 163,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Forma 1 con sphinx\n",
        "\n",
        "def recognize_speech():\n",
        "    recognizer = sr.Recognizer()\n",
        "\n",
        "    try:\n",
        "        with sr.AudioFile(ruta_audio_entrada_convertido) as source:\n",
        "            audio_data = recognizer.record(source)\n",
        "            texto = recognizer.recognize_sphinx(audio_data, language=\"es-ES\")\n",
        "            print(\"texto reconocido:\", texto)\n",
        "    except sr.UnknownValueError:\n",
        "        print(\"No se pudo entender el audio\")\n",
        "    except sr.RequestError as e:\n",
        "        print(\"Error al solicitar resultados de reconocimiento de voz; {0}\".format(e))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 164,
      "metadata": {
        "id": "xEwSWIZcp4zp"
      },
      "outputs": [],
      "source": [
        "# Forma 2 con recognize_gogle\n",
        "\n",
        "def transcribe_audio(ruta_audio_entrada = ruta_audio_entrada_convertido, audio_lang = 'es-ES'):\n",
        "    with sr.AudioFile(ruta_audio_entrada_convertido) as source:\n",
        "        # Escuchar el audio (en inglés)\n",
        "        audio = recognizer.record(source)\n",
        "\n",
        "        # Utilizar Gogle Speech Recognition para transcribir el audio\n",
        "        try:\n",
        "            texto = recognizer.recognize_gogle(audio, audio_lang)\n",
        "            print(\"Transcripción: \", texto)\n",
        "            return texto\n",
        "        except sr.UnknownValueError:\n",
        "            print(\"No se pudo entender el audio\")\n",
        "        except sr.RequestError as e:\n",
        "            print(\"Error al solicitar resultados del servicio Gogle Speech Recognition; {0}\".format(e))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 165,
      "metadata": {},
      "outputs": [],
      "source": [
        "def entrada_audio():\n",
        "    record_audio(audio_file_path = AUDIO_FILES_PATH, filename = FILENAME, duration = DURATION, sample_rate = SAMPLE_RATE)\n",
        "    convert_to_wav(input_file = ruta_audio_entrada, output_file = ruta_audio_entrada_convertido)\n",
        "    texto = recognize_speech()\n",
        "    texto = transcribe_audio(audio_lang = 'es-ES')\n",
        "    return texto"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### c. Identificar tipo de entrada"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 166,
      "metadata": {},
      "outputs": [],
      "source": [
        "entrada_tipo = ''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 167,
      "metadata": {},
      "outputs": [],
      "source": [
        "if entrada_tipo == 'audio':\n",
        "    texto = entrada_audio()\n",
        "elif entrada_tipo == 'texto':\n",
        "    texto = entrada_texto()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AcUSQzM7qsxY"
      },
      "source": [
        "## 2. Procesamiento del Lenguaje Natural\n",
        "\n",
        "___"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 168,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cargar el modelo de spaCy para español\n",
        "\n",
        "nlp = spacy.load(\"es_core_news_sm\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HDaWq5syqu6m"
      },
      "source": [
        "### Preprocesamiento de texto\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 169,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "\"\\n\\n# unidades_medida_peso = ['g', 'gr', 'kg', 'mg', 'µg', 't', 'lb', 'oz', 'cwt',\\n                        #'gramos', 'kilogramos', 'miligramos', 'microgramos',\\n                        #'toneladas', 'libras', 'onzas', 'quintales']\\n\\n\""
            ]
          },
          "execution_count": 169,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Lista de abreviaturas y formas no abreviadas de unidades de medida de peso\n",
        "'''\n",
        "\n",
        "# unidades_medida_peso = ['g', 'gr', 'kg', 'mg', 'µg', 't', 'lb', 'oz', 'cwt',\n",
        "                        #'gramos', 'kilogramos', 'miligramos', 'microgramos',\n",
        "                        #'toneladas', 'libras', 'onzas', 'quintales']\n",
        "\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 170,
      "metadata": {},
      "outputs": [],
      "source": [
        "def procesar_texto(texto):\n",
        "    texto = texto.lower()\n",
        "    texto = re.sub(r'[,\\.;:!\\-*#@$!+_%^&`~]', '', texto)\n",
        "    texto = re.sub(r'\\s+', ' ', texto)\n",
        "\n",
        "    thresgold = 1\n",
        "\n",
        "    doc = nlp(texto)\n",
        "\n",
        "    tokens = [token.texto for token in doc]\n",
        "    stopwords = spacy.lang.es.stop_words.STOP_WORDS\n",
        "    filtered_tokens = [\n",
        "        token.texto for token in doc\n",
        "        if token.texto not in stopwords\n",
        "        and token.pos_ in ('NOUN', 'ADJ', 'ADP')\n",
        "        and len(token.texto) > thresgold\n",
        "        ]#and token.texto not in unidades_medida_peso\n",
        "    lemmas = [token.lemma_ for token in doc if token.texto in filtered_tokens]\n",
        "    pos_tags = [(token.texto, token.pos_) for token in doc if token.texto in filtered_tokens]\n",
        "\n",
        "    return {\n",
        "        \"tokens\": tokens,\n",
        "        \"lemmas\": lemmas,\n",
        "        \"filtered_tokens\": filtered_tokens,\n",
        "        \"pos_tags\": pos_tags,\n",
        "    }"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FLfTLCw2q8IM"
      },
      "source": [
        "\n",
        "**Normalización del texto (eliminación de ruido, corrección ortográfica, etc.)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 171,
      "metadata": {
        "id": "B6Br9PyerAkd"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'texto' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[171], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m texto_analizado \u001b[38;5;241m=\u001b[39m procesar_texto(\u001b[43mtexto\u001b[49m)\n",
            "\u001b[0;31mNameError\u001b[0m: name 'texto' is not defined"
          ]
        }
      ],
      "source": [
        "texto_analizado = procesar_texto(texto)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vrKl19tGq9KJ"
      },
      "source": [
        "**Tokenización**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f5IX1gghrBXD"
      },
      "outputs": [],
      "source": [
        "tokens = texto_analizado['tokens']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xVbV-FF5q-af"
      },
      "source": [
        "**Eliminación de stop words.**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TY1ASrUnrB3I"
      },
      "outputs": [],
      "source": [
        "tokens_filtrados = texto_analizado['filtered_tokens']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lt4d5DQcq_xW"
      },
      "source": [
        "**Lematización y stemming**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZkAeKi67rCfu"
      },
      "outputs": [],
      "source": [
        "lemmas_filtrados = texto_analizado['lemmas']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Etiquetado de estructuras gramaticales:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "pos_tags_filtrados = texto_analizado['pos_tags']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C9ZvYH9dq1GY"
      },
      "source": [
        "### Análisis de texto\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Detectar presencia de palabras de productos lematizadas dentro de dataframe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_frutas_verduras['producto_tokens_lemmas'] = df_frutas_verduras['Producto'].apply(lambda x: procesar_texto(x)['lemmas'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "dict_count_coincidences = {}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for index, row in df_frutas_verduras.iterrows():\n",
        "    for token_producto in row['producto_tokens_lemmas']:\n",
        "        if token_producto in lemmas_filtrados:\n",
        "            if token_producto not in dict_count_coincidences:\n",
        "                dict_count_coincidences[index] = 1\n",
        "            else:\n",
        "                dict_count_coincidences[index] += 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "series_ordered_count_coincidences = pd.Series(dict_count_coincidences)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wSCEB3hpr2y6"
      },
      "source": [
        "Análisis de Sentimiento: Determinar la emoción o tono del texto.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QtrOgErkr4PD"
      },
      "outputs": [],
      "source": [
        "#para futuras versiones"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hzhTpz0qr4lW"
      },
      "source": [
        "Detección de Intenciones (Intent Detection): Identificar la intención del usuario utilizando modelos como BERT, GPT, RASA, etc.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lEYOkzT7r8Pj"
      },
      "outputs": [],
      "source": [
        "# para futuras versiones"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_ibsChXBsNdX"
      },
      "source": [
        "## 3. Gestión del Diálogo\n",
        "\n",
        "___"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zEnB65VssQvq"
      },
      "source": [
        "### Módulo de Gestión de Estado:\n",
        "Llevar un registro del contexto y estado del diálogo para mantener conversaciones coherentes.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "consulta_dict['id_consulta'] = None\n",
        "consulta_dict['id_cliente'] = None\n",
        "consulta_dict['formato_consulta'] = None\n",
        "consulta_dict['transcripción_audio'] = None\n",
        "consulta_dict['entrada_texto'] = texto\n",
        "consulta_dict['entrada_lemas_filtrados'] = lemmas_filtrados\n",
        "consulta_dict['dict_producto_indice_considencias'] = dict_count_coincidences\n",
        "consulta_dict['card_recomendacion'] = None\n",
        "audio_recomendacion = None"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BByh2AXGsVmJ"
      },
      "source": [
        "### Motor de Respuesta:\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j15ewWSasb4F"
      },
      "source": [
        "Generación de Respuestas: Utilizar modelos generativos (como GPT-3) o respuestas predefinidas según las intenciones y entidades detectadas.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_frutas_verduras['Precio'] = df_frutas_verduras['Precio'].apply(common_functions.limpiar_signo_peso)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UjnjzK3gseaL"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Los productos recomendados en base a su consulta y caracteristicas mensionadas son:\n",
            "En el lugar 1: Tomates secos 70 g. en Carrefour a 2229 pesos\n",
            "En el lugar 2: Tomate seco 100 g. en Carrefour a 1799 pesos\n",
            "En el lugar 3: Tomates secos 70 g. en Carrefour a 2229 pesos\n",
            "En el lugar 4: Tomates Secos El Peoncito x 100 g. en La Anonima a 799 pesos\n",
            "En el lugar 5: Tomates Peritas Deshidratados Nature Food x 150 g. en La Anonima a 4750 pesos\n",
            "En el lugar 6: Tomates Deshidratados El Peoncito x 100 g. en La Anonima a 2150 pesos\n",
            "En el lugar 7: Tomates Secos El Peoncito x 100 g. en La Anonima a 4000 pesos\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Asegúrate de que series_ordered_count_coincidences es una Serie ordenada\n",
        "series_ordered_count_coincidences = series_ordered_count_coincidences.sort_values(ascending=False)\n",
        "\n",
        "# Inicialización de la recomendación\n",
        "recomendacion = 'Los productos recomendados en base a su consulta y caracteristicas mensionadas son:\\n'\n",
        "\n",
        "# Lista para almacenar las recomendaciones\n",
        "lista_string_reco_supers_prods = []\n",
        "\n",
        "# Iterar sobre los índices de las coincidencias ordenadas\n",
        "for count, x in enumerate(series_ordered_count_coincidences.index, start=1):\n",
        "    # Extraer los detalles del producto usando el índice\n",
        "    producto, supermercado, precio = df_frutas_verduras.loc[x, ['Producto', 'Supermercado', 'Precio']]\n",
        "    \n",
        "    # Añadir la recomendación a la lista\n",
        "    lista_string_reco_supers_prods.append(f'En el lugar {count}: {producto} en {supermercado} a {precio} pesos\\n')\n",
        "\n",
        "# Concatenar todas las recomendaciones en un solo string\n",
        "recomendacion += ''.join(lista_string_reco_supers_prods)\n",
        "\n",
        "recomendacion = common_functions.redondear_numeros(recomendacion)\n",
        "\n",
        "consulta_dict['card_recomendacion'] = recomendacion\n",
        "\n",
        "print(recomendacion)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xgvv-ETKsenO"
      },
      "source": [
        "Selección de Respuestas: Elegir la mejor respuesta entre varias opciones generadas.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3t1AFBk2sf1P"
      },
      "outputs": [],
      "source": [
        "# Para proximas versiones"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QntMxU6_shpm"
      },
      "source": [
        "### Personalización y Contexto: Adaptar las respuestas en función del historial del usuario y el contexto actual."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MU_3as2dsi2S"
      },
      "outputs": [],
      "source": [
        "# Para proximas versiones"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9-sSu2b0soDe"
      },
      "source": [
        "## 4. texto a voz\n",
        "\n",
        "___"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q5eR9QLTssCK"
      },
      "source": [
        "### Conversión de texto a Voz (TTS): Utilizar servicios como Gogle texto-to-Speech, Amazon Polly, o frameworks como Tacotron para convertir el texto generado en voz.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kzi_CA2tswVF"
      },
      "outputs": [],
      "source": [
        "tts = gTTS(texto=recomendacion, lang='es')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Guardar el audio en un objeto BytesIO\n",
        "audio_buffer = io.BytesIO()\n",
        "tts.write_to_fp(audio_buffer)\n",
        "\n",
        "# Asegurarse de que el puntero esté al principio del buffer\n",
        "audio_buffer.seek(0)\n",
        "\n",
        "# Crear un diccionario y guardar el audio en él\n",
        "consulta_dict = {'recomendacion_audio': audio_buffer}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Funciones separadas para las primeras etapas de reconocimiento del habla: audio, texto\n",
        "def texto(texto):\n",
        "    "
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
